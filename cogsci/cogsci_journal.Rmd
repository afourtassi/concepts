---
title             : "Conceptual Hierarchy in Child-Directed Speech"
shorttitle        : "Conceptual Hierarchy in CDS"
#numbersections: true

author: 
  - name          : "Kyra Wilson"
    affiliation   : "1"
    email         : "kyra.e.wilson22@gmail.com"
    
  - name          : "Michael C. Frank"
    affiliation   : "1"
    email         : "mcfrank@stanford.edu"
    
    
  - name          : "Abdellah Fourtassi"
    affiliation   : "2"
    email         : "abellah.fourtassi@univ-amu.fr"
    address       : "Postal address"
    corresponding : yes    # Define only one corresponding author

affiliation:
  - id            : "1"
    institution   : "Department of Psychology, Stanford University"
  - id            : "2"
    institution   : "Department of Computer Science, Aix-Marseille University"
    

author_note: |

  '***The experiment, sample size, exclusion criteria, and the model’s main predictions were preregistered at https://osf.io/942gv/'
  
  'All data and analytic code are available at https://github.com/afourtassi/concepts' 
  
  'None of the authors have any financial interest or a conflict of interest regarding this work and this submission.'

abstract: |

  "In order for children to understand and reason about the world in a adult-like fashion, they need to learn that conceptual categories are organized in a hierarchical fashion (e.g., a dog is also an animal). The caregiver's linguistic input can play an important role in this learning, and previous studies have documented several cues in parental talk that can help children learn the conceptual hierarchy. However, these previous studies used different datasets and methods which made difficult the systematic comparison of these cues and the study of their relative contribution.  Here, we use a large-scale corpus of child-directed speech and a classification-based evaluation method which allowed us to investigate, within the same framework, various cues that vary radically in terms of how explicit the information they offer is. We found the most explicit cues to be too sparse or too noisy to support robust learning. In contrast, the implicit cues offered, overall, a reliable source of information. Our work confirms the utility of caregiver talk for conveying conceptual information. It provides a stepping stone towards a cognitive model that would use this information in a principled way, leading to testable predictions about children's conceptual development."
 
keywords          : "Conceptual learning, child-directed speech, language and cognition"

header-includes:
   - \usepackage{tipa}
   - \usepackage[sortcites=false,sorting=none]{biblatex}
   - \usepackage{tabularx}
   

bibliography      : ["library.bib"]

figsintext        : yes
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : no

lang              : "english"
class             : "man"
output            : papaja::apa6_pdf 

citation_package: biblatex

---


```{r}
knitr::opts_chunk$set(echo=F, warning=F, cache=F, message=F, sanitize = T)
```

```{r load_packages, include = FALSE}
library(papaja)
library(png)
library(grid)
library(ggplot2)
library(ggthemes)
library(xtable)
options(xtable.comment = FALSE)
library(purrr)
library(readr)
library(ggplot2)
#library(langcog)
library(boot)
#library(lazyeval)
library(dplyr)
library(tidyr)
#library(wordbankr)
library(directlabels)
#library(scales)
library(stringr)
library(lmtest)
#library(rwebppl)
library(jsonlite)
library(nlme)
library(feather)
library(broom)
library(HDInterval)
library(BBmisc)
library(stargazer)
library(lme4)
library(kableExtra)

library(childesr) 
library(dplyr)
library(plyr)
library(ggplot2)
library(tidyr)
library(tidyverse)
library(text2vec)
library(ggcorrplot)
library(factoextra)
library(cluster)
library(wordVectors)
library(reshape2)
library(pROC)
library(extraDistr)
library(NbClust)
library(lme4)
library(memisc)
library(apsrtable)
library(stargazer)
library(ggthemes)
rename <- dplyr::rename
summarise <- dplyr::summarise
select <- dplyr::select

`%!in%` = Negate(`%in%`)

options(tinytex.verbose = TRUE)
```

# Introduction

A hallmark of conceptual knowledge is its hierarchical organization. For example, a husky can be categorized as a dog, but it can also be categorized as a mammal, an animal, or a living being. Hierarchical organization is fundamental to human cognition as it allows, among other things, the generalization of knowledge through inference. For example, upon learning that all living beings are made out of cells, one can conclude that dogs are made of cells, too [e.g., @gelman1988; @markman1989].

There are signs that children as young as 3 years old show hierarchical knowledge in various domains (e.g., animals, clothes, and food). Such signs include using superordinate words like "food" and "animal" according to parental report [@fenson94], using different words to label the same object at different levels of conceptual hierarchy [@clark1997], and being able to extend the meaning of novel words to superordinate categories even controlling for perceptual similarity [@liu2001].

How do children acquire conceptual hierarchy? Early accounts considered
conceptual hierarchy to be the consequence of the emergence of a
domain-general logic of class-inclusion -- in other words grasping the idea that one category can be part of a larger one [@inhelder2013; @sloutsky2015]. Children can acquire hierarchy in a specific domain before mastering the domain-general logic of classes, however [@chi1989; @carey1987; @inagaki2002; @keil1981], suggesting that category-specific input may play a role in this development.

Further, a large body of work has focused on children's _sensorymotor_ experience to account for the development of hierarchcial knwoldege in a specific domain [e.g., @madole1999; @mcclelland2003; @quinn2000; @sloutsky2010; @smith1992]. For example, children may learn that "pigeon" and "raven" are both members of the same category because they look similar. However sensorymotor experience is not the only source of information people use to glean conceptual knowldege. A striking example is the fact that "visual" semantic knowledge in congenitally blind individuals is very similar to that of sighted individuals [e.g., @kim2019; @lewis2019].  

In addition, sensorymotor experience alone may not be suffisant to account for the  entire richeness of taxonomic knowldedge:  Instances of superordinate categories do not necessarily share similar --- sensory accessible --- features, and their learning may require addtional, culture-specifc information. For example, the categories "animal" and "plants" are organized for Groote Eylandt Australian aborigines into three categories: "biological",  "food",  and "totemic" [@waddy1982]. Thus children may need additional input, beyond senseory data, to learn about sthe uperordinate categories of their linguistic community.

Previous research has shown that children also learn about the world fom the _language_ they hear around them for language can provide children with information beyond what they can obtain through sensorimotor experience alone, especially when learning about categories beyond the here and now such as abstract entities [@gelman2009; @harris2012; @csibra2009].

Following this research, the current study tests the extent to which child-directed speech cantains cues that could help children learn conceptual hierarchy. Some previous studies analyzed parent-child interactions and observed that when parents introduce words at the superordinate level, they typically also provide the basic level term [@callanan1985; @blewitt1983; @shipley1983]. For example, parents rarely point to an object and say "this is an animal!" Instead, they usually _anchor_ the superordinate word "animal" at the basic level by saying something along the lines of "This is a duck; a duck is a kind of animal." Such an anchoring strategy provides children with a categorization of the same object at different levels, which may help children understand the underlying hierarchical organization. 

More recent research, prompted by advances in machine learning [@landauer1997; @mikolov2013], found that the statistical distribution of basic-level terms in parental speech can lead to coherent structures at the superordinate level [@huebner2018; @fourtassi2019,  @frermann2016]. For example, though "fish" and "bird" do not look very similar, people talk about them in similar linguistic contexts, typically leading to a similar distributions in speech. Having a shared pattern of co-occurrence (i.e.,  a shared distribution) can cue taxnomic relationship [e.g., @sloutsky2017].  Such distributional information can be a powerful source of conceptual knowledge because it does not require the presence of a lexicalized label for the higher-level category. On this kind of account, categories emerge in a bottom-up fashion as a cluster of related words at the lower-level.

The lingusitic cues reviewed above can be thought of as ends in a continuum that varies from explicit to implicit. The "is-a-kind-of" cue is the most explicit cue since both the terms (i.e., the basic and superordinate labels) and their hierarchical relationship are explicitly stated. The pure distributional cue is the most implicit cue since, on the one hand, the superordinate term is not required and, on the other hand, the hierarchical relationship (that is, the fact that co-occurring basic level terms are part of a higher-level category) can only be induced.

While previous studies have focused on these extremes, other cues are available that have an intermediate status on this continuum. Here, we examine the way parents hint at the hierarchical relationship between two concepts pragmatically without using an explicit inclusion expression. For example, instead of saying "a cow is a kind of animal" parents can say the following (e.g., in the context of a play session): "Do you want a cow or do you want another animal?" (see Table 1 for more examples). We also study whether action affordances provide another -- perhaps more implicit -- cue for category membership. For example, food items could be identified as members of a category by virtue of their compatibility with the verb "eat" and clothing items by their compatibility with "wear." (see Figure \ref{fig:cues}).

 
```{r cues, fig.env = "figure", fig.pos = "h", fig.align = "center", fig.width=7, fig.height=3, fig.cap = "\\label{fig:cues} The cues to conceptual hierachy in the lingusitic input can be understood as falling on a continuum from most explicit to most implicit."}

img <- png::readPNG("figs/cues_paper.png")
grid::grid.raster(img)

```

 
## This study

Previous studies examining individual cues to categorization vary in terms of both the datasets and methods they used, which has made comparison difficult. Implicit cues have
generally been studied using large-scale data and have been evaluated based on their ability to provide an accurate similarity space for words. In contrast, explicit cues have been studied mainly in the context of small-scale experiments and have been tested mainly through counting the frequency of a given linguistic expression (e.g., "X is a kind of Y").

In this work, we make a systematic comparison of explicit and implicit cues using similar methods. In particular, we are interested in quantifyong the infromation provided by each of these cues in spontaenous (rather than scripted) child-directed sppech, using language data from naturalistic child-caregiver interactions [CHILDES 2018.1, @macwhinney2000; @sanchez2019], tested across the entire normative vocabulary. Such comparison is crucial as it allows us, for instance, to formualte hypotheses about the relative role each cue could play in development and about the ability of these cues to scale up to naturalistic data.

To this end, we take a classification approach: We operationalize different cues as features that can be used to compute similarity. We then evaluate this continuous similarity measure by using it for a classification task, deciding whether different basic-level categories are part of the same superordinate category. Thus we can assign a classification accuracy to each cue type. 

The paper is organized as follows. We begin by introducing our child-directeed data and the set of conceptual cues we consider. We then exlain the task and evaluation methods that we use to study and compare the cues. Next, we present the results quantifying the role of each of the four cues and their relative informativeness across development. Finally we discuss our findings in the light of the litterature on early linguistic and conceptaul development. 

<!--While the anchoring mechanism can be effective as an explicit teaching mechanism (see for example Callanan XX), it is unclear whether parents spontaneously use this strategy when introducing super-ordinate terms in a natural context, i.e., in a context where parents are not necessarily aware of the task fixed by the experimenters. In the latter, parents may use what they think is the best teaching strategy to optimize the short-term outcome, rather than reproducing the natural behavior that they use in their spontanepous intercation with children. 

In this work, we explore if the anchoring mechanim scales up to a large corpus of child-directed speech obtained by aggregating transcriptions of parent-child interactions in various contexts. We study many variants of this strategy and we comapre it to another strategy wh

n general, we found little instances of parents anchorinfg super-ordinate terms explicitly at the basic level. We expand the definition of anchoring to include any instance of co-occurrence of X and Y in the same utterance...

-->

<!--- As we indicated above, one of the goals of this work is to test the extent to which parents' bahvior in a controlled context generalizes to a variety of other life situations -->

# Analyses

## Data

We constructed a large-scale corpus by aggregating over all English-language transcripts from CHILDES [@macwhinney2000; @sanchez2019]. We selected all utterances in which the speaker was not tagged as "Child" or "Target_Child" and which were addressed to children up to three years of age. The final corpus contained 1.9 million utterances and 7.9 million words from a collection of 4,939 transcripts across 660 children with an average age of 26.8 months.

We decided to study the six following superordinate categories: "animal", "furniture", "clothes", "food", "toys" and "vehicles". For each of these categories, we used the corresponding basic-level terms available in the English-language MacArthur-Bates Communicative Inventory (CDI) [@fenson94], a parent-report instrument that provides a partial listing and categorization of words produced by children 18--30 months. This set of categories was chosen because it combines all sets of
superordinate categories that had been studied previously and for which CDI data were available. Indeed, most previous experimental work (which we partly reviewed above) used only a subset of these categories for a given study. Further, a Data-driven approach using CDI words and input from CHILDES [@fourtassi2019] led a set of categories made of: "animal", "food," "clothes," and a broad category of "artifacts" which included instances of toys, vehicles, and furniture. Here, we kept the last three categories differentiated as in previous experimental work.

## Cues to Conceptual Hierarchy and their Feature Vectors 

As indicated above, we explored four cues to conceptual hierarchy: "is-a-kind-of", pragmatic, verb affordance-based, and distributional.
We represented each cue as a set of features and we tested how these features allow us to classify basic-level terms into superordinate
categories. To this end, we started by using each cue to derive a feature vector for each basic-level word in the CDI lexicon. In the case where the cue relied on an explicit category marker (i.e., the first three cues), the feature vectors were based on the superordinate categories introduced above. Otherwise (e.g., the fourth cue), the feature vector was an embedding in a high dimensional space derived based on the words' shared pattern of co-occurrence only. In the following, we explain how we computed the feature vectors for each cue (see also Figure \ref{fig:task}).

### Is-a-kind-of

This cue tests the extent to which parents use explicit expressions of class inclusion [@callanan1985]. For each word at the basic label, X,
we construct a feature vector of length 6, where every cell corresponds to a superordinate category, Y, and the entry in each cell corresponds to the frequency with which X appears with Y is in one of the following expressions: "X is a/an Y" or "X is a kind/type/sort of Y" (we kept the same expressions used in previous studies).



### Pragmatic

Parents can express conceptual hierarchy between X and Y without
necessarily using an "is-a-kind-of" expression. In many cases, parents
can hint at this hierarchy using a wide diversity of
linguistic expressions (Table 1). Detecting these expressions at scale is a challenge given their complexity, so as a first attempt to capture this diversity, we relax
grammatical constraints between X to Y, and we keep only the requirement
that X and Y should co-occur.

More concretely, we represent each basic-level term, X, with a feature
vector where each entry represents the frequency with which X co-occurs
with the corresponding superordinate term Y. This co-occurrence is
determined using a fixed window of \(k\) utterances. Values of \(k > 1\)
allow us to capture the case where a relationship between X and Y is
established across more than one utterance. For example:

  -- Mother : What kind of animal is this?
  
  -- Mother : It's a giraffe!


\begin{table}[!htbp] \centering 
\begin{tabularx}{\linewidth}{cXXc}
\hline
\textbf{Category} & Utterance & Interlocutors & Corpus\\
\hline

\textbf{Animals} & Do you want a cow or do you want a different animal? & Mother to Max, 30 months & EllisWeismer\\

\textbf{Furniture} & Furniture means sofas and chairs and... & Mother to Naima, 23 months & Providence\\

\textbf{Clothes} & This is another clothes. See it's just like this shirt. & Investigator to Shem, 30 months & Clark\\

\textbf{Food} & She asked Lily what her favorite food was. If Lily says chocolate I am in trouble. & Mother about Lily, 24 months & Providence\\

\textbf{Toys} & You close the book and we'll get a different toy cause I think you're tired of this. & Mother to child, 13 months & Ambrose\\

\textbf{Vehicles} & The only vehicle you cut out so far is the train. & Mother to Warren, 30 months & Manchester\\

\hline
\end{tabularx}
\caption{\label{tab:pragmatic} Examples of utterances from CHILDES where parents hint at a hierachical relations between basic- and superordinate- level terms.}
\end{table}

### Affordance-based 

The super-ordinate label is not the only category marker that can cue conceptual hierarchy for a basic level term, especially when this category can be characterized by an affordance. For example, "food" can be characterized as the category of things we eat and "clothes" as things we wear. Thus, children can learn that some concepts (e.g., "apple" and "bread") are parts of a higher-level category ("things we eat") by observing how these concepts co-vary with a cue of their common affordance (i.e., the verb "eat").

We computed the feature vectors for this cue as follows. In a first step, we tried to find a verb that could be used as an affordance marker for an entire category. We used "eat" for food, "wear" for clothes, "play" for toys, and "ride" for vehicles. The category "furniture" has no such obvious function verb.  We decided to use the verb “use” because if there were a verb that could fit every member of the category of furniture, it would be that (even though it can also fit things that are not members of the category). For the animal category, we could find no verb that could categorize the instances.

In addition to these verbs, we also identified synonymous verbs for each category that could also signifiy an affordance for the category. However, these verbs were either not found in the corpus (words like "devour" and "utilize" are not used in child directed speech) or they occurred in too many contexts to be useful for categorization ("have" can be used synonymously with "eat", but it has additional meanings that make this not a useable cue). Because of this, only one verb was used for computing the feature vectors for each of the categories.

We detected the concept-affordance relationship, syntactically, based on their occurrence in a verb-complement structure.\footnote{There are more complex structures that could, in principle, be used by parents. We used the simplest as a first approximation, though the performance of this cue could likely be enhanced by considering a wider variety of constructions.} For example, in the utterance "the bird eats the berries", the word "berries" was categorized as "eat"-able. For each basic-level term, we computed a feature vector where entries correspond to the frequency with which this term occurs in a verb-complement relationship with the verb/affordance at hand.

<!-- Besides these "declarative" strategies, our examination of the data showed that parents also use an "interactive" strategy where they ask their children questions such as "What kind of animal is it?" and the child is supposed to respond with a basic-level term. Thus, we also looked for structures of the form "what kind of X", where X is a super-ordinate label.
As is standard in vectorial word representations, we use the cosine between two word vectors as a measure of their similarity. 
-->

### Distributional cue 

Unlike the first three cues, the pure distributional cue is not based on an explicit category marker at the superordinate level. It is based,
instead, on the way basic-level terms are distributed together in speech [@harris1957]. Following previous research [@fourtassi2019], we quantified this cue using the word embedding model Word2Vec [@mikolov2013]. We used this model to represent basic-level words as vectors in a high-dimensional space, representing the distribution of these words in a latent semantic structure.

## Task and Evaluation

Above, we characterized all cues in a vectorial framework. This
framework allows us to directly compare the cues in terms of how they
quantify the similarity between words (defined as the cosine of the
angle formed by their vectors). Based on this similarity, we test the
ability of each cue to predict which pairs of words (from the normative vocabulary) belong to the same superordinate category (e.g., "apple" and "bread") and which pairs
of words belong to different categories (e.g., "apple", "horse"). 


We listed all pairs of basic-level words in the CDI dataset and their cosine similarity (according to each cue). Then, we evaluated the ability of the similarity measures to accurately predict whether the pairs belonged to "same" or "different"
categories, across the full range of possible discrimination thresholds.
We quantified performance in the task using the standard Area Under the ROC curve (hereafter AUC). The AUC score can be interpreted as the probability that, given two pairs of words, of which one is from the same category, the pairs are correctly classified based on the similarity. For each cue, we derived both a global AUC score across all
categories and a category-specific AUC score where we evaluated only the
subset of pairs of words that contained at least an instance of a target
category (see Figure \ref{fig:task}).^[A similar task and evaluation method have been used in previous work to evaluate cues to phonological categories in early development [@fourtassi2013; @fourtassi2014].]


```{r task, fig.env = "figure", fig.pos = "h", fig.align = "center", fig.width=7, fig.height=3, fig.cap = "\\label{fig:task} A schematic description of the task. For each basic-level word (here, `cow') a feature vector is derived from child-directed speech based on how the cue is defined. Here, the vector cells correspond to the superordinate categories. The entry in a given cell (e.g., animal) is incremented when the word `cow' co-occurs with the corresponding category label. The cue is evaluated based on its ability to classify pairs of words into 'same' or 'different' superordinate categories. Here, the pair `cow'-`horse' belongs to the same category. The corresponding vectors should be closer to each other than the vectors of a pair that belongs to different categories (e.g., `cow'-`shirt'). This evaluation is quantified by a standard measure in signal detection theory called the Area Under the ROC Curve (AUC)."}

img <- png::readPNG("figs/task.png")
grid::grid.raster(img)
```


<!--basic-level terms of different super-ordinate categories (the noise). To this end, we evalute the binary classifier that takes as input a list of pairs of basic-level terms and their cosine similarity, and which returns, as output, a score (called the AUROC) which quantifies the accuracy of the cosine similarity, that is, the extent to which it ranks pairs from the same super-ordinate category ("dog", "cat") higher than pairs from different categories ("dog", "chair").-->

# Results 

## Individual Cue Results

Instances of our most explicit cue type, the *"is-a-kind-of" cue*, were so rare that we could not even build feature vectors for basic-level words. In total, we found only four instances, all of them characterizing the "animal" category. Thus, we did not have meaninful results to report for this cue. As for the other cues, Figure \ref{fig:data-all} shows the global AUC score across categories as well as the AUC scores specific to each category. 

```{r data-all, fig.env = "figure", fig.pos = "h", fig.align = "center", fig.width=7, fig.height=3, fig.cap = "\\label{fig:data-all} The Area Under the ROC Curve (AUC) scores of the cues for each category and across all categories ('ALL'). A value of 0.5 represents pure chance, and a value of 1 represents perfect performance. The AUC score can be interpreted as the probability that, given two pairs of basic-level words, of which one is from the same superordinate category, the pairs are correctly classified using their  cue-based similarity."}

auc_all <- feather::read_feather("../saved/auc_combined.feather") %>%
  rename(category = variable,
           AUC = value,
           cue = mode) %>%
  select(-yr)

auc_all$cue <- mapvalues(auc_all$cue, from = c("w2v", "cooccurrence", "verbs"), to = c("Distributional", "Pragmatic", "Affordance"))
auc_all$category <- mapvalues(auc_all$category, from = c("food_drink", "furniture_rooms", "toys", "animals", "clothing", "vehicles"), to = c("food", "furniture", "toys", "animals", "clothes", "vehicles"))

dev <- feather::read_feather("../saved/aggregate.feather") %>%
  filter(age == 3) %>%
  select(-age) %>%
  mutate(category = "ALL")

dev$cue <- mapvalues(dev$cue, from = c("Co-occurrence", "Pragmatic", "Affordance"), to = c("Distributional", "Pragmatic", "Affordance"))

auc_all <- auc_all %>%
  bind_rows(dev)

auc_all$cue <- factor(auc_all$cue, levels = c("Pragmatic", "Affordance", "Distributional"))

auc_all$category <- factor(auc_all$category, levels = c("animals", "clothes", "food", "furniture", "toys",  "vehicles", "ALL"))

ggplot(data=auc_all, aes(x=category, y=AUC, fill=cue)) +
  geom_bar(stat="identity", position=position_dodge()) +
  #geom_bar(data = filter(auc_all, category =='ALL'), stat="identity", position=position_dodge(), alpha=0.5)+
    ylim(0, 1) + 
  geom_hline(yintercept=0.5, linetype = "dashed") +
    theme_few()+
    theme(legend.title = element_text(size=11),
      legend.text=element_text(size=11),
      axis.text = element_text(size = 11, angle = 45))
 
    
```

The accuracy of the *pragmatic cue* was generally low. For this cue, we only report the results with $k=1$, which captures relations between basic and  superrodinate words within a single utterance. Increasing the value of $k$ lead to worse, noisier performance. Regarding the *affordance-based cue*, the accuracy was relatively high for some categories, i.e., "food", "clothes", "vehicles", and "toys" and low for others, i.e., "furniture" and "animal." Finally, the *distributional cue* lead to the best overall results across most superordinate categories.

<!-- \begin{table}[!htbp] \centering  -->
<!-- \caption{\label{tab:regressions} Logistic regressions predicting the binary classification of pairs of basic-level words as belonging to same or different superordiante categories. The predictors are the pairs' similarity measures derived from each cue. We fit a different regression for each superodinate category.}  -->
<!-- \label{}  -->
<!-- \begin{tabular}{@{\extracolsep{5pt}}lcccccc}  -->
<!-- \hline  -->
<!--  & \multicolumn{6}{c}{} \\ -->
<!--  & Animals & Furniture & Toys & Food & Clothing & Vehicles \\  -->
<!-- \hline \\[-1.8ex]  -->
<!--  (Intercept) & $-$2.741$^{***}$ & $-$3.195$^{***}$ & $-$3.244$^{***}$ & $-$2.616$^{***}$ & $-$3.101$^{***}$ & $-$4.663$^{***}$ \\  -->
<!--   & (0.085) & (0.138) & (0.155) & (0.112) & (0.183) & (0.348) \\  -->
<!--   & & & & & & \\  -->
<!--  Co-occurrence & 2.285$^{***}$ & 2.040$^{***}$ & 1.178$^{***}$ & 0.905$^{***}$ & 1.644$^{***}$ & 1.249$^{***}$ \\  -->
<!--   & (0.074) & (0.127) & (0.136) & (0.060) & (0.171) & (0.193) \\  -->
<!--   & & & & & & \\  -->
<!--  Affordance & 0.022 & 0.547$^{***}$ & 0.620$^{***}$ & 2.112$^{***}$ & 1.535$^{***}$ & 2.211$^{***}$ \\  -->
<!--   & (0.057) & (0.094) & (0.113) & (0.092) & (0.153) & (0.245) \\  -->
<!--   & & & & & & \\  -->
<!--  Pragmatic & 0.179$^{***}$ & $-$0.104 & 0.722$^{***}$ & 0.325$^{***}$ & 0.359$^{*}$ & 0.159 \\  -->
<!--   & (0.050) & (0.080) & (0.120) & (0.059) & (0.146) & (0.138) \\  -->
<!--   & & & & & & \\  -->
<!--  \\[-1.8ex]  -->

<!-- \hline \\[-1.8ex]  -->
<!-- \textit{Note:}  & \multicolumn{6}{r}{$^{*}$p$<$0.05; $^{**}$p$<$0.01; $^{***}$p$<$0.001} \\  -->
<!-- \end{tabular}  -->
<!-- \end{table} -->




<!--Thus, this cue can only be informative statistically, i.e., if words from a given super-ordinate category (e.g., "Juice")  co-occur more with the label of this category (i.e., "food") than they do with the label of another category (e.g., "clothes"). -->

## Developmental change?

The results we showed concern cues derived from parental speech to children up to 3
years old, as this is the age when signs of conceptual hierarchy start
to emerge in the developmental literature. But we were also interested
in how information in these cues may change as children grow older.
For this analysis, we followed the same approach as above but included progressively more data in the corpus by adding utterances addressed to older children (Table \ref{tab:development}). Results of this analysis, presented in Figure \ref{fig:dev}, show that the performance of all cues remained stable across development, at least up to 6 years old.

\begin{table}[!htbp] \centering 
\begin{tabularx}{\linewidth}{cXccXX}

\textbf{Age} & Age (months) & Children & Transcripts & Utterances & Words \\
\hline

\textbf{\textless4} & 30.1 & 843 & 6,750 & 2.657 M & 10.827 M\\

\textbf{\textless5} & 33.5 & 971 & 7,889 & 3.093 M & 12.807 M\\

\textbf{\textless6} & 34.8 & 1,046 & 8,654 & 3.221 M & 13.325 M\\

\hline
\end{tabularx}
\caption{\label{tab:development} Information about the corpora used in the analysis of developmental change.}
\end{table}


```{r dev, fig.env = "figure", fig.pos = "!htbp", fig.align = "center", fig.width=3, fig.height=3, fig.cap = "\\label{fig:dev} The Area Under the ROC Curve (AUC) scores for each cue (across all categories) using speech heard by children up to a particular age. A value of 0.5 represents pure chance, and a value of 1 represents perfect performance."}

dev <- feather::read_feather("../saved/aggregate.feather") 

ggplot(data=dev, aes(x=age, y=AUC, col=cue)) +
  geom_point(position=position_dodge()) +
    geom_line() +
    ylim(0, 1) + 
  geom_hline(yintercept=0.5, linetype = "dashed") +
    theme_few()+
    theme(
      aspect.ratio=0.7,
      legend.title = element_text(size=7),
      legend.text=element_text(size=7),
      axis.text = element_text(size = 11)
      ) +
    theme(legend.position = c(0.99, 0.01),
      legend.justification = c("right", "bottom"),
      legend.key.size = unit(0, 'lines'))

```

## Cross-cue results 

Here we explored the extent to which explicit and implicit cues provided
complementary vs. redundant information. To this end, we fit logistic
regressions predicting the binary classification of pairs of basic-level
words as belonging to same or different superordinate categories. The
predictors were the pairs' similarity measures derived from each cue (centered and scaled to maximize comparability; the is-a-kind-of cue was not included due to sparsity). The results of the regressions,
summarized in Table \ref{tab:regressions}, indicate that, overall, each cue remains highly significant when controlling for the other cues. Thus, although distributional cues were highest performing when alone, each cue type provided _non-redundant_ information and the overall classification performance increased when multiple information sources were used.


\begin{table}[!htbp] \centering 
\caption{\label{tab:regressions} Logistic regressions predicting the binary classification of pairs of basic-level words as belonging to same or different superordiante categories. The predictors are the pairs' similarity measures derived from each cue. We fit a different regression for each superodinate category.} 
\label{} 
\begin{tabular}{@{\extracolsep{5pt}}lcccccc} 
\hline 
 & \multicolumn{4}{c}{} \\
 & (Intercept) & Distributional & Affordance & Pragmatic \\ 
\hline \\[-1.8ex] 
  Animals & $-$2.741$^{***}$ & 2.285$^{***}$ & 0.022 & 0.179$^{***}$\\
  & (0.085) & (0.074) & (0.057) & (0.050)\\
  & & & & & & \\
  Furniture & $-$3.195$^{***}$ & 2.040$^{***}$ & 0.547$^{***}$ & $-$0.104\\
  & (0.138) & (0.127) & (0.094) & (0.080) &\\
  & & & & & & \\
  Toys & $-$3.244$^{***}$ & 1.178$^{***}$ &  0.620$^{***}$ & 0.722$^{***}$\\
  & (0.155) & (0.136) & (0.113) & (0.120) &\\
  & & & & & & \\
  Food & $-$2.616$^{***}$ & 0.905$^{***}$ & 2.112$^{***}$ & 0.325$^{***}$\\
  & (0.112) & (0.060) & (0.092) & (0.059)\\
  & & & & & & \\
  Clothing & $-$3.101$^{***}$ & 1.644$^{***}$ & 1.535$^{***}$ & 0.359$^{*}$\\
  & (0.183) & (0.171) & (0.153) & (0.146)\\
  & & & & & & \\
  Vehicles & $-$4.663$^{***}$ & 1.249$^{***}$ & 2.211$^{***}$ & 0.159\\
  & (0.348) & (0.193) & (0.245) & (0.138)\\
  & & & & & & \\
 \\[-1.8ex] 

\hline \\[-1.8ex] 
\textit{Note:}  & \multicolumn{6}{r}{$^{*}$p$<$0.05; $^{**}$p$<$0.01; $^{***}$p$<$0.001} \\ 
\end{tabular} 
\end{table}

# Discussion

A crucial questions in the study of cogntive developemnt is understanding how children acquire the complex hierarchical relationships that characterize mature human conceptual knowledge. A particualrly challenging task is learning how basic-level categories are grouped into abstract superordinate categories. The difficulty of this task stems form the fact that sensorimotor experience does not always provide direct evidence for learning. Here we build on and extend previous work investigating the role of _language_ in learning about abstract concepts [@gelman2009; @harris2012; @csibra2009]. The novelty of our work is that we used  a unified computational framework that has allowed us to directly compare the relative importance of different linguistic cues present in child-directed speech with respect to their ability to help categorize six common superordinate categories. Overall, we found that caregiver talk provides a rich source of information, especially in its implcit form, that chidlren may use in learning category structure.

The most explicit cue --- where caregivers state the relationship between a basic-level term and its superordiante category label (e.g., "a dog is a kind of animal") --- did not scale up well to the naturalistic dataset we used. This finding contrasts with previous work that found this cue in parental speech [@callanan1985; @blewitt1983; @shipley1983]. This contrast can be explained by the fact that these previous studies were done in the context of rather controlled settings and parents were aware of the task (e.g., teaching words at the superordinate level), whereas here we tested a large-scale corpus containing a diversity of situations. Thus, it is possible that, in these previous studies, parents used a teaching strategy that they thought could optimize the short-term outcome (as determined by the experimenter), rather than a strategy that reflects their spontaneous interaction with children in daily life.

<!--Here we used a distributional approach to compare the relative importance of different information sources in categorization of six common superordinate categories. We found that distributional information (as captured by Word2Vec models) and verb affordances were effective and that -- to a lesser extent -- sentential co-occurrence with superordinate labels also contributed positively to classification. Thus, at a high level, our study confirms the utility of caregiver talk for conveying conceptual information and suggests that a rich range of linguistic cues may be available to children in learning category structure. -->

Caregivers can hint at conceptual hierarchy without necessarily stating it explcitly, however (Table 1).  To capture this pragmatic cue, we quantified the co-occurrence between basic-level and superordinate terms within utterances. While this simple operationalization was ment to capture all possible ways the hierarchical relation between two concepts can be expressed linguistically, it also made the representation susceptible to errors, mainly by increasing the rate of false alarms: A basic level term (e.g., "juice") can also co-occur with a superordinate label of which it is not an instance (e.g., "Don't pour the juice on your clothes!"). The rate of such false alarms was quite high, which explaines to overall low  --- though not random --- scores of this cue. From a developmental point of view, this finding highlights the limitation (at scale) of a simple co-occurrence-based strategy: A deeper understanding of the utterance is necessary if chidlren are to learn conceptual hierachy from pragmatic cues while avoiding false alarms. Future work can aim at quantifying such deeper understansing. That said, this is not an easy task since an _automatic_ method that ``understands'' how words are related both semantically and pragmatically is an open computational questions.

Another lingustic cue was based on verb affordance (e.g., basic-level terms for food can all occur as the grammatical objet of the verb "eat"). The acccuracy of the affrodance-based cue was relatively high for the categories which had an obvious verb to cue its affordance, i.e., "food" (eat), "clothes" (wear), "vehicles" (ride), and "toys" (play). The accuracy was low in the case of "furniture" since the verb "use" is not exclusive to this category and can also be used with instances of other categories, leading to false alarms. The accuracy for
"animal" was also low as it was not characterized by any particular affordance verb. \footnote{At the same time, performance of the cue on this category was not totally random as animal instances tend to co-occur consistently with some verbs from other categories (e.g., "ride a horse", "play with the dog", and "eat the chicken").} 

The distributional cue was the most implicit one since it did not require a label for the abstract category. The score for this cue was generally high, including for "animal" and "furniture", two categories that were not accurately captured with any of the previous
cues. This finding suggests that children can learn that certain basic-level terms share common abstract properties by realizing that they have similar distribution in speech, i.e., that they are used in similar contexts. This strategy seems even more plausible for high-level categories that do not have an explicit label, or for which the label could not be available to the young learners (e.g., "animate" vs. "inanimate").

An important finding was that the linguistic cues were largely non-redundant across the categories, suggesing that children can combine several cues to refine their knowlwdege about superordinate concepts. In addition, the cues did not fare similarly across categories, suggesting that children can rely more on different cues to learn different categories, e.g., they may use the affordance-based cue more to learn about "food", "clothes" or "vehilce" and the distributional cue more to learn about "animals" and "furniture."  

For all the cues discussed above, our goal was to test their ability to provide a reliable source of information in child-directed speech. However, our instantiation of the cues abstracted aways the children's cognitive and informaton processsing limitations, providing only an "ideal observer" point of view [@marr1982]. That said, previous experimental work have provided evidence for the cognitive plausivility of the learning mechanisms that underly each of these cues.  

For instace, preschool children ably use the "is-a-kind-of" cue to interpret the meaning of a novel word at the superordinate level [@callanan1989] (though the current study shows this cue not to be pervasive in the natural input).  Both the pragamtic cue and affordance-based cue rely on the ability to track co-occurrence between pairs of words. Extensive research in the last couple of decades has shown that even infants are capable of tracking distributional statistics of various linguistic units [@saffran1996]. In particular, @bannard2008 have shown toddlers encode together in memory collocational words such as "sit" and "chair" and @wojcik2015 have shown that they encode relationships between novel words co-occurring in a sentence. Previous work also provided evidence showing that patterns of co-occurrence do influence children's conceptual associations and inference [@fisher2011; @matlen2015].

The distributional cue requires not only sensititvity to co-occurrence, but also sensitivity to their _shared_ patterns of co-occurrence. For example, learners should be sensitive to the fact that "ravin" and "salmon" co-occur with similar words and phrases such as "lay egg", "live," and "reproduce", although the pair of words "ravin" and "salmon" may not themelves co-occur with each other. There is evidence that even infants are sensitive to shared patterns of co-occurrence (e.g., @lany2011), although the mechanism by which this sensitivity shapes concptual knowledge emerges slowly and continues developing through middle childhood [see review by @unger2021]. 

This work takes a first step towards integrating different cues to conceptual hierachy from caregiver language. Future work should go further by also considering the role of sensorymotor data [@sadeghi2015; @andrews2014; @bruni2014]. Ultimately, the goal would be to integrate both sources in a _cognitive_ model that uses these cues in a principle way. Such a model should make precise developmental predictions about how the cues interact and how their role in learning changes across development.

Another direction for future work is to compare the findings we obtained with data in English to other languages. Understanding variation in children's experience allows us to detrmine which apects of development are universal and which are culture-specific [@medin2010; @rogoff2018]. The case of learning abstract, superodinate categories is an excellent case where such comparison could be very enlightning as we know such categories have both similaritis and differences across cultures (e.g. @waddy1982). Thus, it is crucial that we investigate whether and how variation in caregivers’ language induce variations in children's categorical structure of the world.

<!--Second, we used rough approximations of the potentially more subtle cues that we labeled "pragmatic" and "affordance-based" information. Capturing the structure of knowledge as it is used in natural language is an open computational challenge, but it is possible that more refined cues could improve performance even further. -->

To conclude, our work here suggests the presence of multiple information sources about conceptual structure in children's linguistic environment. Perhaps the most exciting future direction is to synthesize it with knowledge gleaned from children's sensory experience of the world. Such a synthesis will be crucial in making progress on understanding children's conceptual structure. By refining our understanding of linguistic cues to conceptual hierarchy, we hope our work here helps take a first step in this broader project.

<!--
[Discuss the fact that previous studies found anchoring in parental speech, but not this studty]
The goal of this preliminary analysis was to explore the extent to which parents' anchoring strategies reported in previous reseach (typically in a controlled context) generalize to a large scale corpus which contains a variety of situations. In a controlled context, parents are explicitly asked to teach their children instances of conceptual hierachy. While this situation allows us to make precise causal inference, it may prompt parents to use a teaching strategy that optimizes the short-term outcome, rather than a strategy that reflects their spontanepous interaction with children in daily life. They showed that the cues 

The genaral conclusion: Anchoring, when narrowly defined, is not frequent enough, and when braodly defined, is too noisy. 
This does not prove that anchoring is not a valid cue, it is possible that children use an intermediate strategy which accept some expressions of anchoring and rejects others as non-informative, thus increasing the coverage while avoiding noise. This is left for further research.


Along the x-axis we have the categories, and on the y-axis is the AUC value for the category. A value of 1 means the model can classify the categories perfectly, while a value of 0.5 means it has no separative capacity.


In many cases, it may not even be necessary to explicitly mention the superordinate category label,

he intuition behind this formalizton is that words from a given super-ordinate category (e.g., "apple") should co-occur more with the label of this category (i.e., "food") than they do with the label of another category (i.e., "toys"), and thius 


should be more similar to each other than they are to words form another category, i.e.,

(which, in addition, allows us to use)

To determine whether anchoring is a viable cue for the acqusition of conceptual hoerachy, we need to show that the probability of the occurrence of a given super-ordiante categories (e.g., "food") should be higher with their basic-level instances (e.g., "apple") than with instances of different category (e.g., "dog"). Using terms from signal detection theory, the anchoring "signal" should be above "noise".

To conrtrol for this confound (This choice was also motivated by our desire to compare anchoring strategies with bottom-up strategies) We represent each basic-level term with a vector. The dimension of this vector is 5; corresponding to the 5 super-ordinate categories. Each entry in the vector correponds to the frequency with which the basic-level term co-occurs with the super-ordinate term at hand. As is standard in the literature on vectorial word representations, we use the cosine between two vectors (i.e.,  their normalized dot product) as a measure of their similarity. 



We quantify the anchoring strategy by its ability to distinguish basic-level terms of the same super-ordinate category (the signal) from basic-level terms of different super-ordinate categories (the noise). To this end, we evalute the binary classifier that takes as input a list of pairs of basic-level terms and their cosine similarity, and which returns, as output, a score (called the AUROC) which quantifies the accuracy of the cosine similarity, that is, the extent to which it ranks pairs from the same super-ordinate category ("dog", "cat") higher than pairs from different categories ("dog", "chair").

Along the x-axis we have the categories, and on the y-axis is the AUC value for the category. A value of 1 means the model can classify the categories perfectly, while a value of 0.5 means it has no separative capacity.

The genaral conclusion: Anchoring, when narrowly defined, is not frequent enough, and when braodly defined, is too noisy. 
This does not prove that anchoring is not a valid cue, it is possible that children use an intermediate strategy which accept some expressions of anchoring and rejects others as non-informative, thus increasing the coverage while avoiding noise. This is left for further research.
--->

```{r }
density_pragmatic <- feather::read_feather("../saved/density_pragmatic.feather")
density_verb <- feather::read_feather("../saved/density_verb.feather")
density_w2v <- feather::read_feather("../saved/density_w2v.feather")

cues_all <- density_w2v %>%
  rename(cooccurrence = value) %>%
  left_join(density_verb) %>%
  rename(affordance = value) %>%
  left_join(density_pragmatic) %>%
  rename(pragmatic = value) %>%
  mutate(gold = ifelse(measure == "within", 1, 0)) %>%
  filter(!(Var1 == Var2)) %>%
  mutate_at(c('cooccurrence', 'affordance', 'pragmatic'), funs(as.numeric(scale(.)))) 

model_all <- glm(gold ~ cooccurrence  + affordance + pragmatic, family=binomial, data = cues_all)

model_animal <- glm(gold ~ cooccurrence  + affordance + pragmatic, family= binomial, data = filter(cues_all, cat1 == "animals"))
model_furniture <- glm(gold ~ cooccurrence  + affordance + pragmatic, family= binomial, data = filter(cues_all, cat1 == "furniture_rooms"))
model_toy <- glm(gold ~ cooccurrence  + affordance + pragmatic, family= binomial, data = filter(cues_all, cat1 == "toys"))
model_food <- glm(gold ~cooccurrence  + affordance + pragmatic, family= binomial, data = filter(cues_all, cat1 == "food_drink"))
model_clothing <- glm(gold ~ cooccurrence  + affordance + pragmatic, family= binomial, data = filter(cues_all, cat1 == "clothing"))
model_vehicle <- glm(gold ~ cooccurrence  + affordance + pragmatic, family= binomial, data = filter(cues_all, cat1 == "vehicles"))
```


```{r results='asis', include =F}
mytable <- stargazer(model_animal, model_furniture, model_toy, model_food, model_clothing, model_vehicle, keep.stat="n",
          omit.stat = c( "n"),
          
          title            = "Logistic regressions predicting category membership as a function of speech-derived cues.",
          dep.var.labels.include = FALSE,
          #style = "qje",
          model.numbers          = FALSE,
          intercept.bottom = FALSE,
          star.cutoffs = c(0.05, 0.01, 0.001),
          column.labels = c("Animals", "Furniture", "Toys", "Food", "Clothing", "Vehicles")
          )
```


# References
```{r create_r-references}
r_refs(file = "library.bib")
```

\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}





