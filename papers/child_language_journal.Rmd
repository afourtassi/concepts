---
title             : "Conceptual Hierarchy in Child-Directed Speech: Implicit Cues are More Reliable"
shorttitle        : "Conceptual Hierarchy in CDS"
#numbersections: true

author: 
  - name          : "Kyra WILSON"
    affiliation   : "1"
    email         : "kyra.e.wilson22@gmail.com"
    
  - name          : "Michael C. FRANK"
    affiliation   : "1"
    email         : "mcfrank@stanford.edu"
    
    
  - name          : "Abdellah FOURTASSI"
    affiliation   : "2"
    email         : "abellah.fourtassi@univ-amu.fr"
    address       : "Postal address"
    corresponding : yes    # Define only one corresponding author

affiliation:
  - id            : "1"
    institution   : "Department of Psychology, Stanford University"
  - id            : "2"
    institution   : "Department of Computer Science, Aix-Marseille University"
    

author_note: |

  
  'All data and analytic code are available at https://github.com/afourtassi/concepts' 
  
  'None of the authors have any financial interest or a conflict of interest regarding this work and this submission.'

abstract: |

  "In order for children to understand and reason about the world in an adult-like fashion, they need to learn that conceptual categories are organized in a hierarchical fashion (e.g., a dog is also an animal). The caregiver’s linguistic input can play an important role in this learning, and previous studies have documented several cues in parental talk that can help children learn the conceptual hierarchy. However, these previous studies used different datasets and methods which made difficult the systematic comparison of these cues and the study of their relative contribution. Here, we use a large-scale corpus of child-directed speech and a classification-based evaluation method which allowed us to investigate, within the same framework, various cues that vary radically in terms of how explicit the information they offer is. We found the most explicit cues to be too sparse or too noisy to support robust learning. In contrast, the implicit cues offered, overall, a reliable source of information. Our work confirms the utility of caregiver talk for conveying conceptual information. It provides a stepping stone towards a cognitive model that would use this information in a principled way, leading to testable predictions about children’s conceptual development."
 
keywords          : "Conceptual learning, child-directed speech, language and cognition"

header-includes:
   - \usepackage{tipa}
   - \usepackage[sortcites=false,sorting=none]{biblatex}
   - \usepackage{tabularx}
   

bibliography      : ["library.bib"]

figsintext        : no
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : no


lang              : "english"
class             : "man"
output            : papaja::apa6_pdf 

citation_package: biblatex

---


```{r}
knitr::opts_chunk$set(echo=F, warning=F, cache=F, message=F, sanitize = T)
```

```{r load_packages, include = FALSE}
library(papaja)
library(png)
library(grid)
library(ggplot2)
library(ggthemes)
library(xtable)
options(xtable.comment = FALSE)
library(purrr)
library(readr)
library(ggplot2)
#library(langcog)
library(boot)
#library(lazyeval)
library(dplyr)
library(tidyr)
#library(wordbankr)
library(directlabels)
#library(scales)
library(stringr)
library(lmtest)
#library(rwebppl)
library(jsonlite)
library(nlme)
library(feather)
library(broom)
library(HDInterval)
library(BBmisc)
library(stargazer)
library(lme4)
library(kableExtra)

library(childesr) 
library(dplyr)
library(plyr)
library(ggplot2)
library(tidyr)
library(tidyverse)
library(text2vec)
library(ggcorrplot)
library(factoextra)
library(cluster)
library(wordVectors)
library(reshape2)
library(pROC)
library(extraDistr)
library(NbClust)
library(lme4)
library(memisc)
library(apsrtable)
library(stargazer)
library(ggthemes)
rename <- dplyr::rename
summarise <- dplyr::summarise
select <- dplyr::select

`%!in%` = Negate(`%in%`)

options(tinytex.verbose = TRUE)
```

# Introduction

A hallmark human conceptual knowledge is its hierarchical organization. For example, the same entity (e.g.,  a dog) can be considered in a nested strucutre as, e.g., a husky, a dog, a mammal, and an animal. Such hierarchical organization is fundamental to human cognition as it allows, among other things, the generalization of knowledge through inference. For example, upon children's learning that all animals eat, they can conclude that giraffes also eat because the category "giraffe" is *included* in the category "animal" [e.g., @markman1989; @inhelder2013; @sloutsky2010; @murphy2004big].  The current study asks how this hierarchical kniwledge develops? More speicifically, we ask whether children can learn conceptual hierarchy from the *language* they hear around them. 

Although taxonmic knowldge takes time to mature into an adult-like form [@blaye2006categorical; @lucariello1992taxonomic;  @unger2020statistical], research has shown that children as young as 3 years old already show sings of hierarchical knowledge in their early lexicon. For example, observationl studies have found that children use superordinate words like "food" and "animal" [e.g., @fenson94; @frank2021variability], and they use different labels to refer to the *same* object, shifting their coconceptual perspective from one level of abstracness to another (e.g., using the labels "dog" and "animal" to refer to a dog) [e.g., @clark1997]. In more controlled in-lab experiments, preschool children are able, depending on the situation, to interpret the meaning of a novel word (e.g., "dax") either at the basic or at the superordiante level [@callanan1989; @markman1984children]. Critically, chidlren do not simply extend the meanings of words based only on how objects look, e.g., they do not simply use a novel word (e.g., "dax") to name both a car and a truck (but not, say, a banana) because the shape of a car is more similar to that of truck than to that of a banana. Under some circumstances, e.g., when using the label to name mutlipe objects from the target superordinte categoy, they do prefer taxonomic relations even when a perceptually similar --- but taxonomically unrelated --- alternative is available [@liu2001; @gentner1999comparison].

How do children begin acquiring the hierarchical strucure of semantic knowledge? Early accounts considered this learing to be the consequence of the emergence of a *domain-general* logic of class inclusion --- that one category can be part of a larger one --- which develops through middle childhood [@inhelder2013; @winer1980class]. However, and though the logic of classes may represent a mature, adult-like structuring principle of concepts enabling reasoning on both famliar and non-familair domaines, the above-reviewed evidence suggests that children begin showing, much earlier, the ability for hierarchal reasoning in *specific domains* they are familair with or interested in (e.g., the domaine of food or dinosaurs). This fact suggests that the input they receive in specific domaines (whether through perceptual or linguistic means) plays an important role in shaping this organization [See also @chi1989; @carey1987; @inagaki2002]. 

<!--This fact is important for the purpose of the current study as our goal is to study the role of children's linguistic input (in several domaines) on the development of their conceptual organization.-->

Research on the role of children's input in the development of a hierarchical concpetual structure can be summarized into a perceptual/functional-based account and a language-based account (though these accounts are more complementary than mutually exclusive). In the perceptual/functional-based account, children are understood to rely on their first-hand observation of the world, allowing them to from astract concepts using primarily their ability to pick up on simialrities between entities in terms of their perceptual features or functions  [@madole1999; @mcclelland2003; @quinn2000; @sloutsky2010; @sloutsky2015; @smith1992]. Second, using their inductive reasoning skills, they synthesize these concepts into a nested tree structure via perfoming some sort hiereachical clustering [@tenenbaum2006theory; @kemp2007learning; @saxe2019mathematical]. Finally, childern are understood learn how to attribute mutliple labels to the same entity (e.g., dog, mamal, animal), whereby more abstract/broad labels map on to larger regions in the nested tree strucure [@xu2007word].

The current study is, however, best situated within the framework of the language-based account, whereby children are understood to rely, not only on their own perceptual data, but *also* on knowledge transmission from other people. Indeed, superordiante concepts (more than basic-level ones) do not necessarily share similar --- sensory accessible --- features. For example, the categories "animal" and "plants" are organized for Groote Eylandt Australian aborigines rather into three categories: "biological", "food",  and "totemic" [@waddy1982].  Thus, learning conceptual hierarchy requires additional, culture-specific input, primarily via language [@gelman2009; @harris2012; @csibra2009].

<!--To account for the role of domain input in the emergence of abstact knowledge, a large body of research has focused on children's perceptual experience in accountong for the emergence of abstact knowledge more generally [e.g., @madole1999; @mcclelland2003; @quinn2000; @sloutsky2010; @smith1992]. For example, children may learn that "pigeon" and "raven" are both members of the same category because they look similar. However perceptual data is not the only source of information people use to glean conceptual knowledge. A stricking example comes from studies on congenitally blind individuals. Indeed, altough this population does not have access to visual input, their "visual" coneceptual knowledge is, nonethelesss, very similar to that of sighted individuals [e.g., @kim2019], suggesting the role of other sources, especially language (Lewis commentary).

More relevant o  perceptual experience alone may not be sufficient to account for the entire richness of taxonomic knowledge:  Instances of superordinate categories do not necessarily share similar --- sensory accessible --- features, and their learning may require additional, culture-specific information. For example, the categories "animal" and "plants" are organized for Groote Eylandt Australian aborigines into three categories: "biological",  "food",  and "totemic" [@waddy1982]. Thus, children may need additional input, beyond perceptual data, to learn about the superordinate categories of their linguistic community.-->

<!--More relevant to our research question is the fact that children also learn about the world from the language they hear around them, for language can provide children with information beyond what they can obtain through first hand observation alone, especially when learning about categories beyond the here and now such as abstract entities [@gelman2009; @harris2012]. Following this research, the current work investigates the extent to which child-directed speech contains cues that can help children learn conceptual hierarchy. -->

Regarding how children may learn conceotual hierachy from language, observational studies have noted that when parents introduce words at the superordinate level, they typically also provide the basic level term [@callanan1985; @shipley1983]. For example, parents rarely point to an object and say "this is an animal!" Instead, they usually *anchor* the superordinate word "animal" at the basic level by saying something along the lines of "This is a duck; a duck is a kind of animal." Such an anchoring strategy provides children with a categorization of the same object at different levels, which may help them understand the hierarchical organization. 

Also within the language-based account, more recent research, prompted by advances in machine learning [e.g., @mikolov2013; @landauer1997solution], found that the statistical distribution of basic-level terms in parental speech can lead to coherent structures at the superordinate level [@huebner2018; @fourtassi2019;  @frermann2016]. For example, though "fish" and "bird" do not look very similar, people talk about them in similar linguistic contexts, typically leading to similar distributions in speech. Having a shared pattern of co-occurrence cues taxonomic relations and, in fact, several experimental studies have suggested that it does help acquiring such relations in development [@sloutsky2017; @mcneill1963origin; @brown1960word; @ervin1961changes].

These linguistic cues can be thought of as ends in a continuum that varies from explicit to implicit. The "is-a-kind-of" cue is the most explicit cue since both the labels (i.e., the basic and superordinate labels) and their hierarchical relationship are explicitly stated. The "distributional cue" is the most implicit cue since, on the one hand, the superordinate term is not required and, on the other hand, the hierarchical relationship (that is, the fact that co-occurring basic-level terms are part of a higher-level category) can only be induced.  

While the above-reviewed studies have focused on these extremes, other cues have an intermediate status on this continuum. We introduce and test two such cues. The first, which we name the "pragmatic cue," is when parents hint at the hierarchical relationship between two concepts pragmatically without using an explicit inclusion expression. For example, instead of saying "a cow is a kind of animal," parents can say the following: "Do you want a cow or do you want another animal?" (see Table 1 for more examples). In addition, we also study an "Affordance-based cue" whereby action affordances provide another -- and perhaps more implicit -- linguistic cue for category membership. For example, food items could be identified as members of a single superordinate category by virtue of their affordance of "eating" and clothing items by their their affordance of "wearing." (see Figure \ref{fig:cues}).

 
```{r cues, fig.env = "figure", fig.pos = "h", fig.align = "center", fig.width=7, fig.height=3, fig.cap = "\\label{fig:cues} The cues to conceptual hierarchy in the linguistic input can be understood as falling on a continuum from most explicit to most implicit."}

img <- png::readPNG("figs/cues_paper.png")
grid::grid.raster(img)

```

## The current study

Previous studies examining individual linguistic cues to conceptual hierachy have varied in terms of both the datasets and methods they used, which has made comparison difficult, thus hindering cumultative scientific progress on this question. On the one hand, implicit cues have generally been studied using large-scale data and have been evaluated based on their ability to provide an accurate similarity space for words. On the other hand, explicit cues have been studied mainly in the context of small-scale experiments and have been tested mainly by counting the frequency of a given linguistic expression (e.g., "X is a kind of Y"). 

In this study, we make a systematic comparison of explicit and implicit cues using similar methods. In particular, we quantify the information provided by each of these cues in Figure 1 using  spontaneous  -- rather than scripted -- child-directed speech, using language data from naturalistic child-caregiver interactions [CHILDES 2018.1, @macwhinney2000; @sanchez2019]. We test information contaiend in this input data across the entire early lexicon as measured by the MacArthur-Bates Communicative Inventory (CDI) [@fenson94]. We focus on the hierecahical relations that the basic-level terms in this early lexicon bears on six superordiante labels: Animals, Furniture, Clothes, Food, Toys, and Vehicle. This set of superordiante concepts was chosen because it combines all the concepts that had been studied previously and for which CDI data were available. Indeed, most previous experimental work used only a subset of these categories in each given study. Further, a data-driven approach using CDI words and input from CHILDES [@fourtassi2019] led to a set of categories made of "animal", "food," "clothes," and a broad category of "artifacts" which included instances of toys, vehicles, and furniture. Here, we kept the last three categories differentiated as in previous experimental work.

Our research question is to investigate the relative usefulness of each lingusitic cue in providing information that children can utlize for learning hierachical conceptual relationship. To address this question, we proceed as follows. We begin by introducing the child-directed data and the derived linguistic cues for concetual hierachy. We then explain the task and evaluation methods that we use to study and compare these cues. Next, we present the results quantifying the role of each of the four cues and their relative informativeness by 3 three-years old as well as their development up to 6 years old. Finally, we discuss our findings in the light of the literature on early linguistic and conceptual development. 

<!--We take a classification approach: We operationalize different cues as features that can be used to compute similarity. We then evaluate this continuous similarity measure by using it for a classification task, deciding whether different basic-level categories are part of the same superordinate category. Thus we can assign a classification accuracy to each cue type. -->


<!--While the anchoring mechanism can be effective as an explicit teaching mechanism (see for example Callanan XX), it is unclear whether parents spontaneously use this strategy when introducing super-ordinate terms in a natural context, i.e., in a context where parents are not necessarily aware of the task fixed by the experimenters. In the latter, parents may use what they think is the best teaching strategy to optimize the short-term outcome, rather than reproducing the natural behavior that they use in their spontanepous intercation with children. 

In this work, we explore if the anchoring mechanim scales up to a large corpus of child-directed speech obtained by aggregating transcriptions of parent-child interactions in various contexts. We study many variants of this strategy and we comapre it to another strategy wh

n general, we found little instances of parents anchorinfg super-ordinate terms explicitly at the basic level. We expand the definition of anchoring to include any instance of co-occurrence of X and Y in the same utterance...

-->

<!--- As we indicated above, one of the goals of this work is to test the extent to which parents' bahvior in a controlled context generalizes to a variety of other life situations -->

# Methods

## Data

We constructed a large-scale corpus by aggregating all English-language transcripts from CHILDES [@macwhinney2000; @sanchez2019]. We selected all utterances in which the speaker was not tagged as "Child" or "Target_Child." In other wrods, we only keep input from adults, exclusing language produced bvy children. In the main analyses, we limit the input to the speech addressed to children up to three years of age as this is the age where early sings of conceptual hierachy appears  according to the above-reviewd developmental litteraure. That said, we also include results from speech addressed to children up to six years to investigate potential developmental changes in the input. The final corpus contained 1.9 million utterances and 7.9 million words from a collection of 4,939 transcripts across 660 children with an average age of 26.8 months. We decided to study the six following superordinate categories: "animal", "furniture", "clothes", "food", "toys" and "vehicles." For each of these categories, we used the corresponding basic-level terms available in the English-language MacArthur-Bates Communicative Inventory (CDI) [@fenson94], a parent-report instrument that provides a partial listing and categorization of words produced by children 18--30 months. 

## Cues to Conceptual Hierarchy and their Feature Vectors 

As shown in Figure 1, we consider the four linguistic cues to conceptual hierarchy, ranging from most explicit to most implicit: "is-a-kind-of", the  pragmatic, affordance-based, and distributional cues. To faciliate comparison, we represented all these cues as vecotors and we tested how these vecors allow us to classify basic-level terms into superordinate categories.  Below we describe in detail how these vectors were constructed. To summarize, for the "is-a-kind-of" and the pragmatic cues where the hierachical relation relies on the explicit mention of the superordinate words, the vectors were based on the six superordiante words and each cell in the vector correponded to the frequency with which the hierachical relation was found between the basic-level word at hand and the superordinate word in the current cell (see the illustration in Figure \ref{fig:task}). For the affordance-based cue, the vector was constructed in a similar fashion, except that the superordinate terms were replaced with their corresponding affordances (e.g., "eatable" for food and "wearbale" for clothes) and each of the six cells in the vector corresponded to the frquncency with which the basic-level word has been used with the verb that marks the affordance. Finally, the implicit distributional cue does not rely on an explcit category marker. Instead, the feature vector was an "embedding" in a high dimensional space derived based on the words' shared pattern of co-occurrence.

### Is-a-kind-of

This cue tests the extent to which parents use explicit expressions of class inclusion [@callanan1985]. For each word at the basic level, $X$ (e.g., cow),
we construct a feature vector of length 6, where each cell corresponds to one of the 6 superordinate categories under study, $Y_i$ (e.g., animal or food).  The value in cell $i$ corresponds to the frequency with which $X$ appears with $Y_i$ in one of the following expressions: "$X$ is a/an $Y_i$" or "$X$ is a kind/type/sort of $Y_i$" (we kept the same expressions used in the previous study).

### Pragmatic

Parents can express conceptual hierarchy between $X$ and $Y_i$ without necessarily using an explicit "is-a-kind-of"-like expression. In many cases, parents can hint at this hierarchy using a wide diversity of linguistic expressions (see Table 1 for examples from our dataset). The precise and exhaustive characterization of these expressions at scale is an open computational challenge. That said, as a first attempt to capture the diversity with which parents hint at conceptual hierarchy in a pragmatic fashion, we relaxed grammatical constraints between $X$ to $Y_i$, and we kept only the requirement that $X$ and $Y_i$ should co-occur. More concretely, we represent each basic-level term, $X$, with a feature vector where each cell contains the frequency with which X co-occurs
with the corresponding superordinate term $Y_i$ (see Figure \ref{fig:task}, left). This co-occurrence is determined using a fixed window of \(k\) utterances. Values of \(k > 1\)
allow us to capture the case where a relationship between $X$ and $Y_i$ is established across more than one utterance. For example:

  -- Mother: What kind of animal is this?
  
  -- Mother: It's a giraffe!


\begin{table}[!htbp] \centering 

\caption{\label{tab:pragmatic} Examples of utterances from CHILDES where parents hint at hierachical relations between basic- and superordinate- level terms.}

\begin{tabularx}{\linewidth}{cXXc}
\hline
\textbf{Category} & Utterance & Interlocutors & Corpus\\
\hline

\textbf{Animals} & Do you want a cow or do you want a different animal? & Mother to Max, 30 months & EllisWeismer\\

\textbf{Furniture} & Furniture means sofas and chairs and... & Mother to Naima, 23 months & Providence\\

\textbf{Clothes} & This is another clothes. See it's just like this shirt. & Investigator to Shem, 30 months & Clark\\

\textbf{Food} & She asked Lily what her favorite food was. If Lily says chocolate I am in trouble. & Mother about Lily, 24 months & Providence\\

\textbf{Toys} & You close the book and we'll get a different toy cause I think you're tired of this. & Mother to child, 13 months & Ambrose\\

\textbf{Vehicles} & The only vehicle you cut out so far is the train. & Mother to Warren, 30 months & Manchester\\

\hline
\end{tabularx}

\end{table}

### Affordance-based 

The superordinate label is not the only category marker that can cue conceptual hierarchy for a basic level term, especially when this category can also be characterized by its affordance. For example, "food" can be characterized as the category of things we eat and "clothes" as things we wear. Thus, children can learn that some concepts (e.g., "apple" and "bread") are parts of a higher-level category ("things we eat") by observing how these concepts co-vary with a cue of their common affordance (i.e., the verb "eat").  

We computed the feature vectors for affordance-based cue as follows. In a first step, we tried to find a verb that could be used as an affordance marker for an entire category. We used "eat" for food, "wear" for clothes, "play" for toys, and "ride" for vehicles. The category "furniture" has no such obvious function verb.  We decided to use the verb "use" because if there were a verb that could fit every member of the category of furniture, it would be that (even though it can also fit things that are not members of the category). For the animal category, we could find no verb that could categorize the instances. In addition to these verbs, we also identified synonymous verbs for each category that could also signify an affordance for the category. However, these verbs were either not found in the corpus (words like "devour" and "utilize" are not used in child-directed speech) or they occurred in too many contexts to be useful for categorization ("have" can be used synonymously with "eat", but it has additional meanings that make this not a useable cue). Because of this, only one verb was used for computing the feature vectors for each of the categories.

We detected the affordance-based relationships, syntactically, based on occurrence in a verb-complement structure.\footnote{There are more complex structures that could, in principle, be used by parents. Her we used the simplest.} For example, in the utterance "the bird eats the berries," the word "berries" was categorized as "eat"-able. For each basic-level term $X$, we computed a 6-cell-long feature vector where the value in each cell corresponded to the frequency with which$X_i$ occurs in a verb-complement relationship with the verb/affordance $Y_i$ at hand.

<!-- Besides these "declarative" strategies, our examination of the data showed that parents also use an "interactive" strategy where they ask their children questions such as "What kind of animal is it?" and the child is supposed to respond with a basic-level term. Thus, we also looked for structures of the form "what kind of X", where X is a super-ordinate label.
As is standard in vectorial word representations, we use the cosine between two word vectors as a measure of their similarity. 
-->

### Distributional cue 

Unlike the first three cues, the pure distributional cue is not based on an explicit category marker at the superordinate level. It is based, instead, only on the way basic-level terms are distributed together in speech. According to the distributional hypothesis [@harris1957], words that share similar patterns of co-occurrence (or distribution) in speech tend to be semantically close. For example, a child can posit that the words "apple" and "banana" must refer to objects that share semantic properties (and likely belonging to the same superordinate category) because people around them tend to talk about both words in similar context using similar co-occurring words such as "eat," "kitchen," "dessert," and “tree.”

Following previous research [@fourtassi2019], we quantified this cue using a model called Word2Vec, a prediction-based instantiation of the distributional hypothesis [@mikolov2013]. In brief, Word2Vec is a neural network model that maximizes the likelihood of predicting the linguistic context given a word (or predicting a word given the context). For each prediction made, the model derives an error signal obtained by comparing the predicted vs. observed context. The error signal is then backpropagated through the neural network, improving the ability of future predictions. The trained model outputs a high dimensional semantic space where words are represented as continuous vectors (or "embeddings"). Words that predict (or predicted by) similar linguistic context will end up having vectors that are close in this semantic space.  This distributional model and other variants have been applied fruitfully to study language development from word forms to lexical-semantic organisation through word meanings [e.g., @andrews2009integrating; @fourtassi2020word; @frermann2016incremental; @huebner2018; @hills2010; @stella2017; @fourtassi2014]. Here we use Wored2Vec to represent basic-level words as vectors in a high-dimensional space, representing the distribution of these words in a latent semantic structure.

## Task and Evaluation

Above, we explained how we characterized all cues in a unified formal framework. This framework allows us to directly compare the cues thanks to the similarity measures that we can derive from the vector-based representations. The similarity measure is commonly defined as the cosine of the angle formed by two vectors. Using this similarity, we test the ability of each cue to predict which pairs of basic-level words belong to the same superordinate category (e.g., "apple" and "bread") and which pairs of words may belong to different categories (e.g., "apple", "horse") (see Figure \ref{fig:task}, right).

More precisely, we listed all pairs of basic-level words in the CDI dataset and their four cosine similarities (from each of the four cues). Then, we evaluated the ability of each similarity measure to accurately predict whether the pairs belonged to "same" or "different" categories. We quantified performance in the task using a standard signal detection measure called the Area Under the ROC curve (hereafter AUC). The AUC score can be interpreted as the probability that, given two pairs of words (e.g., "apple"/"bread" and "apple"/"horse"), of which one is from the same category (i.e., "apple"/"bread"), the pairs are correctly classified. This probalisic interpretation indicates that AUC values range between 0.5 (i.e., the cue is performing at chance) and 1 (i.e., the cue is perferct). We derived both a global AUC score across all six categories and a category-specific AUC score where we evaluated only the subset of pairs of words that contained at least an instance of a target category.^[A similar task and evaluation method have been used in previous work to evaluate cues to phonological categories in early development [@fourtassi2013; @fourtassi2014].]


```{r task, fig.env = "figure", fig.pos = "h", fig.align = "center", fig.width=7, fig.height=3, fig.cap = "\\label{fig:task} A schematic description of the task. For each basic-level word (here, `cow') a feature vector is derived from child-directed speech based on how the cue is defined. Here, the vector cells correspond to the superordinate categories. The entry in a given cell (e.g., animal) is incremented when the word `cow' co-occurs with the corresponding category label. The cue is evaluated based on its ability to classify pairs of words into 'same' or 'different' superordinate categories. Here, the pair `cow'-`horse' belongs to the same category. The corresponding vectors should be closer to each other than the vectors of a pair that belongs to different categories (e.g., `cow'-`shirt'). This evaluation is quantified by a standard measure in signal detection theory called the Area Under the ROC Curve (AUC)."}

img <- png::readPNG("figs/task.png")
grid::grid.raster(img)
```


<!--basic-level terms of different super-ordinate categories (the noise). To this end, we evalute the binary classifier that takes as input a list of pairs of basic-level terms and their cosine similarity, and which returns, as output, a score (called the AUROC) which quantifies the accuracy of the cosine similarity, that is, the extent to which it ranks pairs from the same super-ordinate category ("dog", "cat") higher than pairs from different categories ("dog", "chair").-->

# Results 

## Individual Cue Results

Instances of the most explicit cue type, the *"is-a-kind-of" cue*, were so rare that we could not even build feature vectors for basic-level words. In total, we found only four instances, all of them characterizing the "animal" category. Thus, we did not have meaningful results to report for this cue. As for the other cues, Figure \ref{fig:data-all} shows the global AUC score across categories as well as the AUC scores specific to each category. 

```{r data-all, fig.env = "figure", fig.pos = "h", fig.align = "center", fig.width=7, fig.height=3, fig.cap = "\\label{fig:data-all} The Area Under the ROC Curve (AUC) scores of the cues for each category and across all categories ('ALL'). A value of 0.5 represents pure chance, and a value of 1 represents perfect performance. The AUC score can be interpreted as the probability that, given two pairs of basic-level words, of which one is from the same superordinate category, the pairs are correctly classified using their  cue-based similarity."}

auc_all <- feather::read_feather("../saved/auc_combined.feather") %>%
  rename(category = variable,
           AUC = value,
           cue = mode) %>%
  select(-yr)

auc_all$cue <- mapvalues(auc_all$cue, from = c("w2v", "cooccurrence", "verbs"), to = c("Distributional", "Pragmatic", "Affordance"))
auc_all$category <- mapvalues(auc_all$category, from = c("food_drink", "furniture_rooms", "toys", "animals", "clothing", "vehicles"), to = c("food", "furniture", "toys", "animals", "clothes", "vehicles"))

dev <- feather::read_feather("../saved/aggregate.feather") %>%
  filter(age == 3) %>%
  select(-age) %>%
  mutate(category = "ALL")

dev$cue <- mapvalues(dev$cue, from = c("Co-occurrence", "Pragmatic", "Affordance"), to = c("Distributional", "Pragmatic", "Affordance"))

auc_all <- auc_all %>%
  bind_rows(dev)

auc_all$cue <- factor(auc_all$cue, levels = c("Pragmatic", "Affordance", "Distributional"))

auc_all$category <- factor(auc_all$category, levels = c("animals", "clothes", "food", "furniture", "toys",  "vehicles", "ALL"))

ggplot(data=auc_all, aes(x=category, y=AUC, fill=cue)) +
  geom_bar(stat="identity", position=position_dodge()) +
  #geom_bar(data = filter(auc_all, category =='ALL'), stat="identity", position=position_dodge(), alpha=0.5)+
    ylim(0, 1) + 
  geom_hline(yintercept=0.5, linetype = "dashed") +
    theme_few()+
    theme(legend.title = element_text(size=11),
      legend.text=element_text(size=11),
      axis.text = element_text(size = 11, angle = 45))
 
    
```

The accuracy of the *pragmatic cue* was generally low. For this cue, we only report the results with $k=1$, which captures relations between basic and superordinate words within a single utterance. Increasing the value of $k$ has led to worse, noisier performance. Regarding the *affordance-based cue*, the accuracy was relatively high for some categories, i.e., "food", "clothes", "vehicles," and "toys" and low for others, i.e., "furniture" and "animal." Finally, the *distributional cue* leads to the best overall results across most superordinate categories.

<!-- \begin{table}[!htbp] \centering  -->
<!-- \caption{\label{tab:regressions} Logistic regressions predicting the binary classification of pairs of basic-level words as belonging to same or different superordiante categories. The predictors are the pairs' similarity measures derived from each cue. We fit a different regression for each superodinate category.}  -->
<!-- \label{}  -->
<!-- \begin{tabular}{@{\extracolsep{5pt}}lcccccc}  -->
<!-- \hline  -->
<!--  & \multicolumn{6}{c}{} \\ -->
<!--  & Animals & Furniture & Toys & Food & Clothing & Vehicles \\  -->
<!-- \hline \\[-1.8ex]  -->
<!--  (Intercept) & $-$2.741$^{***}$ & $-$3.195$^{***}$ & $-$3.244$^{***}$ & $-$2.616$^{***}$ & $-$3.101$^{***}$ & $-$4.663$^{***}$ \\  -->
<!--   & (0.085) & (0.138) & (0.155) & (0.112) & (0.183) & (0.348) \\  -->
<!--   & & & & & & \\  -->
<!--  Co-occurrence & 2.285$^{***}$ & 2.040$^{***}$ & 1.178$^{***}$ & 0.905$^{***}$ & 1.644$^{***}$ & 1.249$^{***}$ \\  -->
<!--   & (0.074) & (0.127) & (0.136) & (0.060) & (0.171) & (0.193) \\  -->
<!--   & & & & & & \\  -->
<!--  Affordance & 0.022 & 0.547$^{***}$ & 0.620$^{***}$ & 2.112$^{***}$ & 1.535$^{***}$ & 2.211$^{***}$ \\  -->
<!--   & (0.057) & (0.094) & (0.113) & (0.092) & (0.153) & (0.245) \\  -->
<!--   & & & & & & \\  -->
<!--  Pragmatic & 0.179$^{***}$ & $-$0.104 & 0.722$^{***}$ & 0.325$^{***}$ & 0.359$^{*}$ & 0.159 \\  -->
<!--   & (0.050) & (0.080) & (0.120) & (0.059) & (0.146) & (0.138) \\  -->
<!--   & & & & & & \\  -->
<!--  \\[-1.8ex]  -->

<!-- \hline \\[-1.8ex]  -->
<!-- \textit{Note:}  & \multicolumn{6}{r}{$^{*}$p$<$0.05; $^{**}$p$<$0.01; $^{***}$p$<$0.001} \\  -->
<!-- \end{tabular}  -->
<!-- \end{table} -->




<!--Thus, this cue can only be informative statistically, i.e., if words from a given super-ordinate category (e.g., "Juice")  co-occur more with the label of this category (i.e., "food") than they do with the label of another category (e.g., "clothes"). -->

## Developmental change?

<!--The results we showed concern cues derived from parental speech to children up to 3
years old, as this is the age when signs of conceptual hierarchy start
to emerge in the developmental literature. But -->


<!-- The main goal of the current study is to quantify the linguistic cues that children could use to initiate the learnig of conceptual hiererachy in their emerging lexicon. -->

The results above are based on child-drected speech up to three years old. As we mentioned earlier, this choice was based on research showing that this is the age when early signs of conceptual hiererachy emerge in children's lexicon. That said, several studies have documented changes in child-directed speech beyond that age [e.g., @jiang2022exploring; @huttenlocher2010sources; @kunert2011adaptation], and here we ask whether and how our four linguistic cues undergo changes as children grow older and the contexts of their social intercations become more sopisticated. We followed the same approach as above but included progressively more data in the corpus by adding utterances addressed to older children up to 6 years old (the age after which data become very sparse in the dataset CHILDES) (Table \ref{tab:development}). This cumulative way to study change parallels the cumulative nature of chidlren's linguistic exeperience.  The results are summarized in Figure \ref{fig:dev}: They show that the performance of all cues remained stable across development.

\begin{table}[!htbp] \centering 
\caption{\label{tab:development} Information about the corpora used in the analysis of developmental change.}
\begin{tabularx}{\linewidth}{cXccXX}

\textbf{Age} & Age (months) & Children & Transcripts & Utterances & Words \\
\hline

\textbf{\textless4} & 30.1 & 843 & 6,750 & 2.657 M & 10.827 M\\

\textbf{\textless5} & 33.5 & 971 & 7,889 & 3.093 M & 12.807 M\\

\textbf{\textless6} & 34.8 & 1,046 & 8,654 & 3.221 M & 13.325 M\\

\hline
\end{tabularx}

\end{table}


```{r dev, fig.env = "figure", fig.pos = "!htbp", fig.align = "center", fig.width=3, fig.height=3, fig.cap = "\\label{fig:dev} The Area Under the ROC Curve (AUC) scores for each cue (across all categories) using speech heard by children up to a particular age. A value of 0.5 represents pure chance, and a value of 1 represents perfect performance."}

dev <- feather::read_feather("../saved/aggregate.feather") 

ggplot(data=dev, aes(x=age, y=AUC, col=cue)) +
  geom_point(position=position_dodge()) +
    geom_line() +
    ylim(0, 1) + 
  geom_hline(yintercept=0.5, linetype = "dashed") +
    theme_few()+
    theme(
      aspect.ratio=0.7,
      legend.title = element_text(size=7),
      legend.text=element_text(size=7),
      axis.text = element_text(size = 11)
      ) +
    theme(legend.position = c(0.99, 0.01),
      legend.justification = c("right", "bottom"),
      legend.key.size = unit(0, 'lines'))

```

## Cross-cue results 

The analyses above explored how the cues fare individually. Here we investigate the extent to which they provide complementary vs. redundant information when combined. To this end, we fit six logistic regressions, one for each superordinate categories In all the regressions, the dependent variable was the binary classification of pairs of basic-level words as belonging to same or different superordinate categories. The independents variables were the four similarity measures derived from the four cues. The results of the regressions,
summarized in Table \ref{tab:regressions}, indicate that, overall, each cue remains highly significant when controlling for the other cues. Thus, overall, the cues provided _non-redundant_ information to category membership.
<!--and the overall classification performance increased when multiple information sources were used.
-->

\begin{table}[!htbp] \centering 
\caption{\label{tab:regressions} Logistic regressions predicting the binary classification of pairs of basic-level words as belonging to same or different superordinate categories. The predictors are the pairs' similarity measures derived from each cue. We fit a different regression for each superordinate category. The predictors were centered and scaled for comparability.} 
\label{} 
\begin{tabular}{@{\extracolsep{5pt}}lcccccc} 
\hline 
 & \multicolumn{4}{c}{} \\
 & (Intercept) & Distributional & Affordance & Pragmatic \\ 
\hline \\[-1.8ex] 
  Animals & $-$2.741$^{***}$ & 2.285$^{***}$ & 0.022 & 0.179$^{***}$\\
  & (0.085) & (0.074) & (0.057) & (0.050)\\
  & & & & & & \\
  Furniture & $-$3.195$^{***}$ & 2.040$^{***}$ & 0.547$^{***}$ & $-$0.104\\
  & (0.138) & (0.127) & (0.094) & (0.080) &\\
  & & & & & & \\
  Toys & $-$3.244$^{***}$ & 1.178$^{***}$ &  0.620$^{***}$ & 0.722$^{***}$\\
  & (0.155) & (0.136) & (0.113) & (0.120) &\\
  & & & & & & \\
  Food & $-$2.616$^{***}$ & 0.905$^{***}$ & 2.112$^{***}$ & 0.325$^{***}$\\
  & (0.112) & (0.060) & (0.092) & (0.059)\\
  & & & & & & \\
  Clothing & $-$3.101$^{***}$ & 1.644$^{***}$ & 1.535$^{***}$ & 0.359$^{*}$\\
  & (0.183) & (0.171) & (0.153) & (0.146)\\
  & & & & & & \\
  Vehicles & $-$4.663$^{***}$ & 1.249$^{***}$ & 2.211$^{***}$ & 0.159\\
  & (0.348) & (0.193) & (0.245) & (0.138)\\
  & & & & & & \\
 \\[-1.8ex] 

\hline \\[-1.8ex] 
\textit{Note:}  & \multicolumn{6}{r}{$^{*}$p$<$0.05; $^{**}$p$<$0.01; $^{***}$p$<$0.001} \\ 
\end{tabular} 
\end{table}

# Discussion

A crucial question in the study of both language and cognitive development is understanding how children acquire the complex hierarchical relationships that characterize mature human semantic knowledge. A particularly challenging task is learning how basic-level terms are related to abstract superordinate concepts. The difficulty of this task stems from the fact that first-hand perceptual experience does not always provide direct evidence for learning. (Can language provide an additional) 

Here we build on and extend previous work investigating the role of _language_ in learning about abstract concepts [@gelman2009; @harris2012]. The novelty of our work is that we used  a unified computational framework that has allowed us to directly compare the relative importance of different linguistic cues present in child-directed speech with respect to their ability to help categorize the taxonmic relations with respect to six common superordinate categories. 

<!--Overall, we found that caregiver talk provides a rich source of information, especially in its implicit form, that children may use in learning category structure.-->

## The relative usefulness of cues to concepual hiearchy in child-directed speech 

The most explicit cue --- where caregivers state the relationship between a basic-level term and its superordinate category label (e.g., "a dog is a kind of animal") --- did not scale up well to the naturalistic dataset we used. This finding contrasts with previous work that found this cue in parental speech [@callanan1985; @shipley1983]. This contrast can be explained by the fact that these previous studies were done in the context of rather controlled settings and parents were aware of the task (e.g., teaching words at the superordinate level), whereas here we tested a corpus of larely *spontaneous* speech. 

<!--Thus, it is possible that, in these previous studies, parents used a teaching strategy that they thought could optimize the short-term outcome (as determined by the experimenter), rather than a strategy that reflects their spontaneous interaction with children in daily life.-->

<!--Here we used a distributional approach to compare the relative importance of different information sources in categorization of six common superordinate categories. We found that distributional information (as captured by Word2Vec models) and verb affordances were effective and that -- to a lesser extent -- sentential co-occurrence with superordinate labels also contributed positively to classification. Thus, at a high level, our study confirms the utility of caregiver talk for conveying conceptual information and suggests that a rich range of linguistic cues may be available to children in learning category structure. -->

Caregivers can hint at conceptual hierarchy without necessarily stating it explicitly, however (see Table 1).  To capture this pragmatic cue, we quantified the co-occurrence between basic-level and superordinate terms within utterances. While this simple operationalization was meant to capture all possible ways the hierarchical relationship between two concepts can be expressed linguistically, it also made the representation susceptible to errors, mainly by increasing the rate of false alarms: A basic level term (e.g., "juice") can also co-occur with a superordinate label of which it is not an instance (e.g., "Don't pour the juice on your clothes!"). The rate of such false alarms was quite high, which explains the overall low  --- though not random --- scores of this cue. From a developmental point of view, this finding highlights the limitation (at scale) of a simple co-occurrence-based strategy: A deeper understanding of the utterance is necessary if children are to learn conceptual hierarchy from pragmatic cues while avoiding false alarms. Future work should aim at providing a more refined computational implementation of this cues. While the ability of state-of-the-art language models in making general pragmatic inference is still low, modeling work can still be fruitful when focused on the specific task on infering taxonomic relations. We are not aware of a work that has managed to automatically infer this knowledge reliably when the taxonomic relation is not mentioned explcitly. That said, reseach in child development can take inspiration  from on going attemps to acheive this goal in the field of Natural Language Porcessing (e.g., Chami, I., Abu-El-Haija, S., Perozzi, B., Ré, C., and Murphy, K., 2020; Le, M., Roller, S., Papaxanthos, L., Kiela, D., & Nickel, M., 2019; Zhang, H., Liu, X., Pan, H., Ke, H., Ou, J., Fang, T., & Song, Y., 2022).

<!--Future work can aim at quantifying such deeper understanding. That said, this is not an easy task since an _automatic_ method that ``understands'' how words are related both semantically and pragmatically is an open computational question.-->

Another linguistic cue we tesed is based on affordances (e.g., basic-level terms for food are "eat"-able and can detecteed as such if they occur as the grammatical object of the verb "eat"). The accuracy of the affordance-based cue was relatively high for the categories which had an obvious verb to cue its affordance, i.e., "food" (eat), "clothes" (wear), "vehicles" (ride), and "toys" (play). The accuracy was low in the case of "furniture" since the verb "use" is not exclusive to this category and can also be used with instances of other categories, leading to false alarms. The accuracy for "animal" was also low as it was not characterized by any particular verb. \footnote{At the same time, the performance of the cue on this category was not totally random because animal instances tend to co-occur consistently with some verbs from other categories (e.g., "ride a horse", "play with the dog", and "eat the chicken").} 

Finally, the pure distributional cue was the most implicit one since it did not rely on a label or any other linguistic marker for the abstract category. The score for this cue was generally high, including for "animal" and "furniture", two categories that were not reliably captured with any of the previous cues. This finding suggests that children can learn that certain basic-level terms share common abstract properties by realizing that they have a similar distribution in speech, i.e., that they are used in similar contexts. This strategy seems even more plausible for high-level categories that do not have an explicit label, or for which the label could not be available to the young learners (e.g., "animate" vs. "inanimate").

In addtion to these insights that we obtained by testing each cue indivudually, we also found that the cues were largely non-redundant across most categories, suggesting that children can combine several cues to complement their learning. Further, the cues did not fare similarly across categories, suggesting that children can rely more on different cues to learn different categories, e.g., they may use the affordance-based cue more to learn about "food", "clothes" or "vehicle" and the distributional cue more to learn about "animals" and "furniture." (use examples here,..) 

## Possible learning mechainsms

For all the cues discussed above, our goal was to test their ability to provide a reliable source of information in child-directed speech. However, our instantiation of the cues abstracted away from the children's cognitive and information processing limitations, providing only an "ideal observer" point of view [@marr1982]. That said, several experimental studies have provided evidence for the cognitive plausibility of the learning mechanisms that underly each of these cues.  

For instance, preschool children ably use the "is-a-kind-of" cue to interpret the meaning of a novel word at the superordinate level [@callanan1989] (though the current study shows this cue to be highly impoverished in natural input).  Both the pragmatic cue and affordance-based cue rely on the ability to track co-occurrence between pairs of words. Extensive research in the last couple of decades has shown that even infants are capable of tracking distributional statistics of various linguistic units [@saffran1996]. In particular, @bannard2008 have shown toddlers encode together in memory collocational words such as "sit" and "chair" and @wojcik2015 have shown that they encode relationships between novel words co-occurring in a sentence. The distributional cue, on the other hand, requires not only sensitivity to word co-occurrence (as with the pragmatic and affordanc-based cues) but also sensitivity to the words' _shared_ patterns of co-occurrence. For example, learners should be sensitive to the fact that "raven" and "salmon" co-occur with similar words and phrases such as "lay egg", "live," and "reproduce", although the pair of words "raven" and "salmon" may not themselves co-occur with each other. There is some evidence that even infants are sensitive to shared patterns of co-occurrence [e.g., @lany2011].

Note, however, that while the detection of reliably co-occurring pair of labels can create a mental association (via simple associative mechanims), it is not enough how this association would develop into becomong a taxonmic relation (as opposed to, say, a thematic relation). In other words, detecting co-occurrence is a necessary but not a sufficient condition for the learning of conceptual *hierarchy*. To make full advantage of the affordance-base cue, it is important to also understand the syntactic relations (i.e., verb-complement structure). For the pragmatic cue, it is crucial to also make inferences about the speaker's intended relationship between basic and super-ordinate terms given the context. Indeed, the fact that our simple implementation of the pragamric cue based on mere co-occurence has led to poor formance is a strong testimony to the need for this additional, higer-level inference. 

As for the pure distributional cue, there is a priori no additional information (syntacic or extra-linguistic) that can help chidlren induce conceptual hierachy byond information about word co-occurrence. On this account, the accumulation of direct co-occurrence in children's memory leads to the realization (perhasp also triggered by cognitive maturation, e.g., Bauer & San Souci, 2010; Savic et al., 2022) that some words share similar pattern of co-occurrence (e.g., that "deer" and "zebra" co-occur in simialr lingusitic contexts), which then foster the creation of a taxonmic link (i.e., "deer" and "zebra" are instance of a single higher-level conceptual category, e.g., "animal") (McNeill, 1963; Sloutsky, 2017; Unger et al., 2020). It is still unclear what precise mechainsm can explains how the shared patterns of co-occurrence between two labels may give rise of a taxnomic link relating these labels as belonging to a single super-ordinated category (but see @unger2021 for a review of some proposals).

## Conclusion and future work 

This work takes a first step towards integrating different cues to conceptual hierarchy from caregiver language. Future work should go further by also considering the role of sensorimotor data [@andrews2014; @bruni2014]. Ultimately, the goal would be to integrate both sources into a _cognitive_ model that uses these cues in a principle way. Such a model should make precise developmental predictions about how the cues interact and how their role in learning changes across development.

Another direction for future work is to compare the findings we obtained with data in English to other languages. Understanding variation in children's experiences allows us to determine which aspects of development are universal and which are culture-specific [@rogoff2018]. The case of learning abstract, superordinate categories is an excellent case where such comparison could be very enlightening as we know such categories have both similarities and differences across cultures [e.g. @waddy1982]. Thus, it is crucial that we investigate whether and how variation in caregivers’ language induces variations in children's categorical structure of the world.

<!--Second, we used rough approximations of the potentially more subtle cues that we labeled "pragmatic" and "affordance-based" information. Capturing the structure of knowledge as it is used in natural language is an open computational challenge, but it is possible that more refined cues could improve performance even further. -->

<!--To conclude, our work here suggests the presence of multiple information sources about conceptual structure in children's linguistic environment. Perhaps the most exciting future direction is to synthesize it with knowledge gleaned from children's sensory experience of the world. Such a synthesis will be crucial in making progress in understanding children's conceptual structure. By refining our understanding of linguistic cues to conceptual hierarchy, we hope our work here helps take a first step in this broader project.-->

<!--
[Discuss the fact that previous studies found anchoring in parental speech, but not this studty]
The goal of this preliminary analysis was to explore the extent to which parents' anchoring strategies reported in previous reseach (typically in a controlled context) generalize to a large scale corpus which contains a variety of situations. In a controlled context, parents are explicitly asked to teach their children instances of conceptual hierachy. While this situation allows us to make precise causal inference, it may prompt parents to use a teaching strategy that optimizes the short-term outcome, rather than a strategy that reflects their spontanepous interaction with children in daily life. They showed that the cues 

The genaral conclusion: Anchoring, when narrowly defined, is not frequent enough, and when braodly defined, is too noisy. 
This does not prove that anchoring is not a valid cue, it is possible that children use an intermediate strategy which accept some expressions of anchoring and rejects others as non-informative, thus increasing the coverage while avoiding noise. This is left for further research.


Along the x-axis we have the categories, and on the y-axis is the AUC value for the category. A value of 1 means the model can classify the categories perfectly, while a value of 0.5 means it has no separative capacity.


In many cases, it may not even be necessary to explicitly mention the superordinate category label,

he intuition behind this formalizton is that words from a given super-ordinate category (e.g., "apple") should co-occur more with the label of this category (i.e., "food") than they do with the label of another category (i.e., "toys"), and thius 


should be more similar to each other than they are to words form another category, i.e.,

(which, in addition, allows us to use)

To determine whether anchoring is a viable cue for the acqusition of conceptual hoerachy, we need to show that the probability of the occurrence of a given super-ordiante categories (e.g., "food") should be higher with their basic-level instances (e.g., "apple") than with instances of different category (e.g., "dog"). Using terms from signal detection theory, the anchoring "signal" should be above "noise".

To conrtrol for this confound (This choice was also motivated by our desire to compare anchoring strategies with bottom-up strategies) We represent each basic-level term with a vector. The dimension of this vector is 5; corresponding to the 5 super-ordinate categories. Each entry in the vector correponds to the frequency with which the basic-level term co-occurs with the super-ordinate term at hand. As is standard in the literature on vectorial word representations, we use the cosine between two vectors (i.e.,  their normalized dot product) as a measure of their similarity. 



We quantify the anchoring strategy by its ability to distinguish basic-level terms of the same super-ordinate category (the signal) from basic-level terms of different super-ordinate categories (the noise). To this end, we evalute the binary classifier that takes as input a list of pairs of basic-level terms and their cosine similarity, and which returns, as output, a score (called the AUROC) which quantifies the accuracy of the cosine similarity, that is, the extent to which it ranks pairs from the same super-ordinate category ("dog", "cat") higher than pairs from different categories ("dog", "chair").

Along the x-axis we have the categories, and on the y-axis is the AUC value for the category. A value of 1 means the model can classify the categories perfectly, while a value of 0.5 means it has no separative capacity.

The genaral conclusion: Anchoring, when narrowly defined, is not frequent enough, and when braodly defined, is too noisy. 
This does not prove that anchoring is not a valid cue, it is possible that children use an intermediate strategy which accept some expressions of anchoring and rejects others as non-informative, thus increasing the coverage while avoiding noise. This is left for further research.
--->

```{r }
density_pragmatic <- feather::read_feather("../saved/density_pragmatic.feather")
density_verb <- feather::read_feather("../saved/density_verb.feather")
density_w2v <- feather::read_feather("../saved/density_w2v.feather")

cues_all <- density_w2v %>%
  rename(cooccurrence = value) %>%
  left_join(density_verb) %>%
  rename(affordance = value) %>%
  left_join(density_pragmatic) %>%
  rename(pragmatic = value) %>%
  mutate(gold = ifelse(measure == "within", 1, 0)) %>%
  filter(!(Var1 == Var2)) %>%
  mutate_at(c('cooccurrence', 'affordance', 'pragmatic'), funs(as.numeric(scale(.)))) 

model_all <- glm(gold ~ cooccurrence  + affordance + pragmatic, family=binomial, data = cues_all)

model_animal <- glm(gold ~ cooccurrence  + affordance + pragmatic, family= binomial, data = filter(cues_all, cat1 == "animals"))
model_furniture <- glm(gold ~ cooccurrence  + affordance + pragmatic, family= binomial, data = filter(cues_all, cat1 == "furniture_rooms"))
model_toy <- glm(gold ~ cooccurrence  + affordance + pragmatic, family= binomial, data = filter(cues_all, cat1 == "toys"))
model_food <- glm(gold ~cooccurrence  + affordance + pragmatic, family= binomial, data = filter(cues_all, cat1 == "food_drink"))
model_clothing <- glm(gold ~ cooccurrence  + affordance + pragmatic, family= binomial, data = filter(cues_all, cat1 == "clothing"))
model_vehicle <- glm(gold ~ cooccurrence  + affordance + pragmatic, family= binomial, data = filter(cues_all, cat1 == "vehicles"))
```


```{r results='asis', include =F}
mytable <- stargazer(model_animal, model_furniture, model_toy, model_food, model_clothing, model_vehicle, keep.stat="n",
          omit.stat = c( "n"),
          
          title            = "Logistic regressions predicting category membership as a function of speech-derived cues.",
          dep.var.labels.include = FALSE,
          #style = "qje",
          model.numbers          = FALSE,
          intercept.bottom = FALSE,
          star.cutoffs = c(0.05, 0.01, 0.001),
          column.labels = c("Animals", "Furniture", "Toys", "Food", "Clothing", "Vehicles")
          )
```


# References
```{r create_r-references}
r_refs(file = "library.bib")
```


\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}





