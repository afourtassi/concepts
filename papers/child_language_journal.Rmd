---
title             : "Conceptual Hierarchy in Child-Directed Speech: Implicit Cues are More Reliable"
shorttitle        : "Conceptual Hierarchy in CDS"
#numbersections: true

author: 
  - name          : "Kyra WILSON"
    affiliation   : "1"
    email         : "kyra.e.wilson22@gmail.com"
    
  - name          : "Michael C. FRANK"
    affiliation   : "1"
    email         : "mcfrank@stanford.edu"
    
    
  - name          : "Abdellah FOURTASSI"
    affiliation   : "2"
    email         : "abellah.fourtassi@univ-amu.fr"
    address       : "Postal address"
    corresponding : yes    # Define only one corresponding author

affiliation:
  - id            : "1"
    institution   : "Department of Psychology, Stanford University"
  - id            : "2"
    institution   : "Department of Computer Science, Aix-Marseille University"
    

author_note: |

  
  'All data and analytic code are available at https://github.com/afourtassi/concepts' 
  
  'A preliminary version of this work was presented in the cognitive science society conference and appeared in the  non-archival proceedings as: 
  
  Fourtassi, A., Wilson, K.,  & Frank, M., C. (2020). Discovering Conceptual Hierarchy Through Explicit and Implicit Cues in Child-Directed Speech. In Proceedings of the 42nd Annual Meeting of the Cognitive Science Society'

abstract: |

  In order for children to understand and reason about the world in an adult-like fashion, they need to learn that conceptual categories are organized in a hierarchical fashion (e.g., a dog is also an animal). While children learn from their first-hand observation of the world, social knowledge transmission via language can also play an important role in this learning. Previous studies have documented several cues in parental talk that can help children learn about conceptual hierarchy. However, these studies have used different datasets and methods which has made it difficult to compare the relative usefulness of various linguistic cues to conceptual knowledge and to test whether they scale up to the naturalistic speech. Here, we studies a large-scale corpus of English child-directed speech and used a unified classification-based evaluation method which allowed us to investigate and compare cues that vary in terms of how explicit the information they offer is. We found the more explicit cues to be too sparse or too noisy in child-directed speech, making them unlikely to support robust learning. In contrast, the implicit cues offered a more reliable source of information starting from the linguistic input heard by 3 years and up to 6 years of age. Our work confirms the utility of caregiver talk for conveying conceptual information and supporting the development of early taxonomic knowledge. It provides a first step toward a cognitive model that would combine perceptual- and language-based mechanisms, leading to testable predictions about children’s conceptual development.
 
keywords          : "Conceptual learning, child-directed speech, language and cognition"

header-includes:
   - \usepackage{tipa}
   - \usepackage[sortcites=false,sorting=none]{biblatex}
   - \usepackage{tabularx}
   

bibliography      : ["library.bib"]

figsintext        : no
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : no


lang              : "english"
class             : "man"
output            : papaja::apa6_pdf 

citation_package: biblatex

---


```{r}
knitr::opts_chunk$set(echo=F, warning=F, cache=F, message=F, sanitize = T)
```

```{r load_packages, include = FALSE}
library(papaja)
library(png)
library(grid)
library(ggplot2)
library(ggthemes)
library(xtable)
options(xtable.comment = FALSE)
library(purrr)
library(readr)
library(ggplot2)
#library(langcog)
library(boot)
#library(lazyeval)
library(dplyr)
library(tidyr)
#library(wordbankr)
library(directlabels)
#library(scales)
library(stringr)
library(lmtest)
#library(rwebppl)
library(jsonlite)
library(nlme)
library(feather)
library(broom)
library(HDInterval)
library(BBmisc)
library(stargazer)
library(lme4)
library(kableExtra)

library(childesr) 
library(dplyr)
library(plyr)
library(ggplot2)
library(tidyr)
library(tidyverse)
library(text2vec)
library(ggcorrplot)
library(factoextra)
library(cluster)
library(wordVectors)
library(reshape2)
library(pROC)
library(extraDistr)
library(NbClust)
library(lme4)
library(memisc)
library(apsrtable)
library(stargazer)
library(ggthemes)
rename <- dplyr::rename
summarise <- dplyr::summarise
select <- dplyr::select

`%!in%` = Negate(`%in%`)

options(tinytex.verbose = TRUE)
```

# Introduction

A hallmark of human conceptual knowledge is its hierarchical organization. For example, the same entity (e.g.,  a dog) can be considered in a nested structure as, e.g., a husky, a dog, a mammal, and an animal. Such hierarchical organization is fundamental to human cognition as it allows, among other things, the generalization of knowledge through inference. For example, upon children's learning that all animals eat, they can conclude that giraffes also eat because the category "giraffe" is *included* in the category "animal" [e.g., @markman1989; @inhelder2013; @sloutsky2010; @murphy2004big].  The current study asks how this hierarchical knowledge develops? More specifically, we ask whether children can learn conceptual hierarchy from the *language* they hear around them. 

Although taxonomic knowledge takes time to mature into an adult-like form [@blaye2006categorical; @lucariello1992taxonomic;  @unger2020statistical], researchers have noted that children as young as 3 years old already show signs of hierarchical knowledge in their early lexicon. For example, observational studies have found that children use superordinate words like "food" and "animal" [e.g., @fenson94; @frank2021variability], and they use different labels to refer to the *same* object, shifting their conceptual perspective from one level of abstractness to another (e.g., using the labels "dog" and "animal" to refer to a dog) [e.g., @clark1997]. In more controlled in-lab experiments, preschool children are able, depending on the situation, to interpret the meaning of a novel word (e.g., "Dax") either at the basic or at the superordinate level [@callanan1989; @markman1984children]. Critically, children do not simply extend the meanings of words based only on how objects look, e.g., they do not simply use a novel word (e.g., "Dax") to name both a car and a truck (but not, say, a banana) because the shape of a car is more similar to that of a truck than to that of a banana. Under some circumstances, e.g., when using the label to name multiple objects from the target superordinate category, they do prefer taxonomic relations even when a perceptually similar --- but taxonomically unrelated --- alternative is available [@liu2001; @gentner1999comparison].

How do children begin acquiring the hierarchical structure of semantic knowledge? Early accounts considered this learning to be the consequence of the emergence of a *domain-general* logic of class inclusion --- that one category can be part of a larger one --- which develops through middle childhood [@inhelder2013; @winer1980class]. However, and though the logic of classes may represent a mature, adult-like structuring principle of concepts enabling reasoning on both familiar and unfamiliar domains, the above-reviewed evidence suggests that children begin showing, much earlier, the ability for hierarchical reasoning in *specific domains* they are familiar with or interested in (e.g., the domain of food or dinosaurs). This fact suggests that the input they receive in specific domains (whether through perceptual or linguistic means) plays an important role in shaping this organization [See also @chi1989; @carey1987; @inagaki2002]. 

<!--This fact is important for the purpose of the current study as our goal is to study the role of children's linguistic input (in several domains) on the development of their conceptual organization.-->

Research on the role of children's input in the development of a hierarchical conceptual structure can be summarized into a perceptual/functional-based account and a language-based account (though these accounts are more complementary than mutually exclusive). In the perceptual/functional-based account, children are understood to rely on their first-hand observation of the world, allowing them to form abstract concepts using primarily their ability to pick up on similarities between entities in terms of their perceptual features or functions  [@madole1999; @mcclelland2003; @quinn2000; @sloutsky2010; @sloutsky2015; @smith1992]. Second, using their inductive reasoning skills, they synthesize these concepts into a nested tree structure via performing some sort of hierarchical clustering [@tenenbaum2006theory; @kemp2007learning; @saxe2019mathematical]. Finally, children are understood to learn how to attribute multiple labels to the same entity (e.g., dog, mammal, animal), whereby more abstract/broad labels map onto larger regions in the nested tree structure [@xu2007word].

The current study is, however, best situated within the framework of the language-based account, whereby children are understood to rely, not only on their own perceptual data but *also* on knowledge transmission from other people. Indeed, superordinate concepts (more than basic-level ones) do not necessarily share similar --- sensory accessible --- features. For example, the categories "animal" and "plants" are organized for Groote Eylandt Australian aborigines rather into three categories: "biological", "food",  and "totemic" [@waddy1982].  Thus, learning conceptual hierarchy requires additional, culture-specific input, primarily via language [@gelman2009; @harris2012; @csibra2009].

<!--To account for the role of domain input in the emergence of abstract knowledge, a large body of research has focused on children's perceptual experience in accounting for the emergence of abstract knowledge more generally [e.g., @madole1999; @mcclelland2003; @quinn2000; @sloutsky2010; @smith1992]. For example, children may learn that "pigeon" and "raven" are both members of the same category because they look similar. However perceptual data is not the only source of information people use to glean conceptual knowledge. A striking example comes from studies on congenitally blind individuals. Indeed, although this population does not have access to visual input, their "visual" conceptual knowledge is, nonetheless, very similar to that of sighted individuals [e.g., @kim2019], suggesting the role of other sources, especially language (Lewis commentary).

More relevant or perceptual experience alone may not be sufficient to account for the entire richness of taxonomic knowledge:  Instances of superordinate categories do not necessarily share similar --- sensory accessible --- features, and their learning may require additional, culture-specific information. For example, the categories "animal" and "plants" are organized for Groote Eylandt Australian aborigines into three categories: "biological",  "food",  and "totemic" [@waddy1982]. Thus, children may need additional input, beyond perceptual data, to learn about the superordinate categories of their linguistic community.-->

<!--More relevant to our research question is the fact that children also learn about the world from the language they hear around them, for language can provide children with information beyond what they can obtain through first hand observation alone, especially when learning about categories beyond the here and now such as abstract entities [@gelman2009; @harris2012]. Following this research, the current work investigates the extent to which child-directed speech contains cues that can help children learn conceptual hierarchy. -->

Regarding how children may learn conceptual hierarchy from language, observational studies have noted that when parents introduce words at the superordinate level, they typically also provide the basic level term [@callanan1985; @shipley1983]. For example, parents rarely point to an object and say "this is an animal!" Instead, they usually *anchor* the superordinate word "animal" at the basic level by saying something along the lines of "This is a duck; a duck is a kind of animal." Such an anchoring strategy provides children with a categorization of the same object at different levels, which may help them understand the hierarchical organization. 

Also within the language-based account, more recent research, prompted by advances in machine learning [e.g., @mikolov2013; @landauer1997solution], found that the statistical distribution of basic-level terms in parental speech can lead to coherent structures at the superordinate level [@huebner2018; @fourtassi2019;  @frermann2016]. For example, though "fish" and "bird" do not look very similar, people talk about them in similar linguistic contexts, typically leading to similar distributions in speech. Having a shared pattern of co-occurrence cues taxonomic relations and, in fact, several experimental studies have suggested that it does help to acquire such relations in development [@sloutsky2017; @mcneill1963origin; @brown1960word; @ervin1961changes].

These linguistic cues can be thought of as ends in a continuum that varies from explicit to implicit. The "is-a-kind-of" cue is the most explicit cue since both the labels (i.e., the basic and superordinate labels) and their hierarchical relationship are explicitly stated. The "distributional cue" is the most implicit cue since, on the one hand, the superordinate term is not required and, on the other hand, the hierarchical relationship (that is, the fact that co-occurring basic-level terms are part of a higher-level category) can only be induced.  

While the above-reviewed studies have focused on these extremes, one can think of other cues that have an intermediate status on this continuum. We introduce and test two such cues. The first, which we name the "pragmatic cue," is when parents hint at the hierarchical relationship between two concepts pragmatically without using an explicit inclusion expression. For example, instead of saying "a cow is a kind of animal," parents can say the following: "Do you want a cow or do you want another animal?" (see Table 1 for more examples). In addition, we also study an "Affordance-based cue" whereby action affordances provide another -- and perhaps more implicit -- linguistic cue for category membership. For example, food items could be identified as members of a single superordinate category by virtue of their affordance of "eating" and clothing items by their affordance of "wearing." (see Figure \ref{fig:cues}).

 
```{r cues, fig.env = "figure", fig.pos = "h", fig.align = "center", fig.width=7, fig.height=3, fig.cap = "\\label{fig:cues} The cues to conceptual hierarchy in the linguistic input can be understood as falling on a continuum from most explicit to most implicit."}

img <- png::readPNG("figs/cues_paper.png")
grid::grid.raster(img)

```

## The current study

Previous studies examining individual linguistic cues to conceptual hierarchy have varied in terms of both the datasets and methods they used, which has made comparison difficult, thus hindering cumulative scientific progress on this question. On the one hand, implicit cues have generally been studied using large-scale data and have been evaluated based on their ability to provide an accurate similarity space for words. On the other hand, explicit cues have been studied mainly in the context of small-scale experiments and have been tested mainly by counting the frequency of a given linguistic expression (e.g., "X is a kind of Y"). 

In this study, we make a systematic comparison of explicit and implicit cues using similar methods. In particular, we quantify the information provided by each of these cues in Figure 1 using spontaneous  -- rather than scripted -- child-directed speech, using language data from naturalistic child-caregiver interactions [CHILDES 2018.1, @macwhinney2000; @sanchez2019]. We test information contained in this input data across the entire early lexicon as measured by the MacArthur-Bates Communicative Inventory (CDI) [@fenson94]. We focus on the hierarchical relations that the basic-level terms in this early lexicon bear on six superordinate labels: Animals, Furniture, Clothes, Food, Toys, and vehicles. This set of superordinate concepts was chosen because it combines all the concepts that had been studied previously and for which CDI data were available. Further, a data-driven approach using CDI words and input from CHILDES [@fourtassi2019] led to a set of categories made of "animal", "food," "clothes," and a broad category of "artifacts'' which included instances of toys, vehicles, and furniture. Here, we kept the last three categories differentiated as in previous experimental work.

Our research question is to investigate the relative usefulness of each linguistic cue in providing information that children can utilize for learning hierarchical conceptual relationships. To address this question, we proceed as follows. We begin by introducing the child-directed data and the derived linguistic cues for conceptual hierarchy. We then explain the task and evaluation methods that we use to study and compare these cues. Next, we present the results quantifying the role of each of the four cues and their relative informativeness by 3 three years of age as well as their change in development up to 6 years old. Finally, we discuss our findings in light of the literature on early linguistic and conceptual development. 


<!--We take a classification approach: We operationalize different cues as features that can be used to compute similarity. We then evaluate this continuous similarity measure by using it for a classification task, deciding whether different basic-level categories are part of the same superordinate category. Thus we can assign a classification accuracy to each cue type. -->


<!--While the anchoring mechanism can be effective as an explicit teaching mechanism (see for example Callanan XX), it is unclear whether parents spontaneously use this strategy when introducing super-ordinate terms in a natural context, i.e., in a context where parents are not necessarily aware of the task fixed by the experimenters. In the latter, parents may use what they think is the best teaching strategy to optimize the short-term outcome, rather than reproducing the natural behavior that they use in their spontanepous intercation with children. 

In this work, we explore if the anchoring mechanim scales up to a large corpus of child-directed speech obtained by aggregating transcriptions of parent-child interactions in various contexts. We study many variants of this strategy and we comapre it to another strategy wh

n general, we found little instances of parents anchorinfg super-ordinate terms explicitly at the basic level. We expand the definition of anchoring to include any instance of co-occurrence of X and Y in the same utterance...

-->

<!--- As we indicated above, one of the goals of this work is to test the extent to which parents' bahvior in a controlled context generalizes to a variety of other life situations -->

# Methods

## Data

We constructed a large-scale corpus by aggregating all English-language transcripts from CHILDES [@macwhinney2000; @sanchez2019]. We selected all utterances in which the speaker was not tagged as "Child" or "Target_Child." In other words, we only keep input from adults, excluding language produced by children. In the main analyses, we limit the input to the speech addressed to children up to three years of age as this is the age where early signs of conceptual hierarchy appear according to the above-reviewed developmental literature. That said, we also include results from speech addressed to children up to six years to investigate potential developmental changes in the input. The final corpus contained 1.9 million utterances and 7.9 million words from a collection of 4,939 transcripts across 660 children with an average age of 26.8 months. We decided to study the six following superordinate categories: "animal", "furniture", "clothes", "food", "toys" and "vehicles." For each of these categories, we used the corresponding basic-level terms available in the English-language MacArthur-Bates Communicative Inventory (CDI) [@fenson94], a parent-report instrument that provides a partial listing and categorization of words produced by children 18--30 months. 

## Cues to Conceptual Hierarchy and their Feature Vectors 

As shown in Figure 1, we consider the four linguistic cues to conceptual hierarchy, ranging from most explicit to most implicit: "is-a-kind-of", the pragmatic, affordance-based, and distributional cues. To facilitate comparison, we represented all these cues as vectors and we tested how these vectors allow us to classify basic-level terms into superordinate categories.  Below we describe in detail how these vectors were constructed. To summarize, for the "is-a-kind-of" and the pragmatic cues where the hierarchical relation relies on the explicit mention of the superordinate words, the vectors were based on the six superordinate words, and each cell in the vector corresponded to the frequency with which the hierarchical relation was found between the basic-level word at hand and the superordinate word in the current cell (see the illustration in Figure \ref{fig:task}, left). For the affordance-based cue, the vector was constructed in a similar fashion, except that the superordinate terms were replaced with their corresponding affordances (e.g., "eatable" for food and "wearable" for clothes) and each of the six cells in the vector corresponded to the frequency with which the basic-level word has been used with the verb that marks the affordance. Finally, the implicit distributional cue does not rely on an explicit category marker. Instead, the feature vector was an "embedding" in a high dimensional space derived based on the words' shared pattern of co-occurrence.

### Is-a-kind-of

This cue tests the extent to which parents use explicit expressions of class inclusion [@callanan1985]. For each word at the basic level, $X$ (e.g., cow),
we construct a feature vector of length 6, where each cell corresponds to one of the 6 superordinate categories under study, $Y_i$ (e.g., animal or food).  The value in cell $i$ corresponds to the frequency with which $X$ appears with $Y_i$ in one of the following expressions: "$X$ is a/an $Y_i$" or "$X$ is a kind/type/sort of $Y_i$" (we kept the same expressions used in the previous study).

### Pragmatic

Parents can express conceptual hierarchy between $X$ and $Y_i$ without necessarily using an explicit "is-a-kind-of"-like expression. In many cases, parents can hint at this hierarchy using a wide diversity of linguistic expressions (see Table 1 for examples from our dataset). The precise and exhaustive characterization of these expressions at scale is an open computational challenge. That said, as a first attempt to capture the diversity with which parents hint at conceptual hierarchy in a pragmatic fashion, we relaxed grammatical constraints between $X$ to $Y_i$, and we kept only the requirement that $X$ and $Y_i$ should co-occur. More concretely, we represent each basic-level term, $X$, with a feature vector where each cell contains the frequency with which X co-occurs
with the corresponding superordinate term $Y_i$ (see Figure \ref{fig:task}, left). This co-occurrence is determined using a fixed window of \(k\) utterances. Values of \(k > 1\)
allow us to capture the case where a relationship between $X$ and $Y_i$ is established across more than one utterance. For example:

  -- Mother: What kind of animal is this?
  
  -- Mother: It's a giraffe!


\begin{table}[!htbp] \centering 

\caption{\label{tab:pragmatic} Examples of utterances from CHILDES where parents hint at hierarchical relations between basic- and superordinate-level terms.}

\begin{tabularx}{\linewidth}{cXXc}
\hline
\textbf{Category} & Utterance & Interlocutors & Corpus\\
\hline

\textbf{Animals} & Do you want a cow or do you want a different animal? & Mother to Max, 30 months & EllisWeismer\\

\textbf{Furniture} & Furniture means sofas and chairs and... & Mother to Naima, 23 months & Providence\\

\textbf{Clothes} & This is another clothes. See it's just like this shirt. & Investigator to Shem, 30 months & Clark\\

\textbf{Food} & She asked Lily what her favorite food was. If Lily says chocolate I am in trouble. & Mother about Lily, 24 months & Providence\\

\textbf{Toys} & You close the book and we'll get a different toy cause I think you're tired of this. & Mother to child, 13 months & Ambrose\\

\textbf{Vehicles} & The only vehicle you cut out so far is the train. & Mother to Warren, 30 months & Manchester\\

\hline
\end{tabularx}

\end{table}

### Affordance-based 

The superordinate label is not the only category marker that can cue conceptual hierarchy for a basic level term, especially when this category can also be characterized by its affordance. For example, "food" can be characterized as the category of things we eat and "clothes" as things we wear. Thus, children can learn that some concepts (e.g., "apple" and "bread") are parts of a higher-level category ("things we eat") by observing how these concepts co-vary with a cue of their common affordance (i.e., the verb "eat").  

We computed the feature vectors for the affordance-based cue as follows. In a first step, we tried to find a verb that could be used as an affordance marker for an entire category. We used "eat" for food, "wear" for clothes, "play" for toys, and "ride" for vehicles. The category "furniture" has no such obvious function verb.  We decided to use the verb "use" because if there were a verb that could fit every member of the category of furniture, it would be that (even though it can also fit things that are not members of the category). For the animal category, we could find no verb that could categorize the instances. In addition to these verbs, we also identified synonymous verbs for each category that could also signify an affordance for the category. However, these verbs were either not found in the corpus (words like "devour" and "utilize" are not used in child-directed speech) or they occurred in too many contexts to be useful for categorization ("have" can be used synonymously with "eat", but it has additional meanings that make this not a useable cue). Because of this, only one verb was used for computing the feature vectors for each of the categories.

We detected the affordance-based relationships, syntactically, based on occurrence in a verb-complement structure.\footnote{There are more complex structures that could, in principle, be used by parents. Here we used the simplest.} For example, in the utterance "the bird eats the berries," the word "berries" was categorized as "eat"-able. For each basic-level term $X$, we computed a 6-cell-long feature vector where the value in each cell corresponded to the frequency with which$X_i$ occurs in a verb-complement relationship with the verb/affordance $Y_i$ at hand.

<!-- Besides these "declarative" strategies, our examination of the data showed that parents also use an "interactive" strategy where they ask their children questions such as "What kind of animal is it?" and the child is supposed to respond with a basic-level term. Thus, we also looked for structures of the form "what kind of X", where X is a super-ordinate label.
As is standard in vectorial word representations, we use the cosine between two word-vectors as a measure of their similarity. 
-->

### Distributional cue 

Unlike the first three cues, the pure distributional cue is not based on an explicit category marker at the superordinate level. It is based, instead, only on the way basic-level terms are distributed together in speech. According to the distributional hypothesis [@harris1957], words that share similar patterns of co-occurrence (or distribution) in speech tend to be semantically close. For example, a child can posit that the words "apple" and "banana" must refer to objects that share semantic properties (and likely belong to the same superordinate category) because people around them tend to talk about both words in similar context using similar co-occurring words such as "eat," "kitchen," "dessert," and “tree.”

Following previous research [@fourtassi2019], we quantified this cue using a model called Word2Vec, a prediction-based instantiation of the distributional hypothesis [@mikolov2013]. In brief, Word2Vec is a neural network model that maximizes the likelihood of predicting the linguistic context given a word (or predicting a word given the context). For each prediction made, the model derives an error signal obtained by comparing the predicted vs. observed context. The error signal is then backpropagated through the neural network, improving the ability of future predictions. The trained model outputs a high-dimensional semantic space where words are represented as continuous vectors (or "embeddings"). Words that predict (or are predicted by) similar linguistic contexts will end up having vectors that are close in this semantic space.  This distributional model and other variants have been applied fruitfully to study language development from word forms to the lexical-semantic organization through word meanings [e.g., @andrews2009integrating; @fourtassi2020word; @frermann2016incremental; @huebner2018; @hills2010; @stella2017; @fourtassi2014]. Here we use Wored2Vec to represent basic-level words as vectors in a high-dimensional space, representing the distribution of these words in a latent semantic structure.

## Task and Evaluation

Above, we explained how we characterized all cues in a unified formal framework. This framework allows us to directly compare the cues thanks to the similarity measures that we can derive from the vector-based representations. The similarity measure is commonly defined as the cosine of the angle formed by two vectors. Using this similarity, we test the ability of each cue to predict which pairs of basic-level words belong to the same superordinate category (e.g., "apple" and "bread") and which pairs of words may belong to different categories (e.g., "apple", "horse") (see Figure \ref{fig:task}, right).

More precisely, we listed all pairs of basic-level words in the CDI dataset and their four cosine similarities (from each of the four cues). Then, we evaluated the ability of each similarity measure to accurately predict whether the pairs belonged to "same" or "different" categories. We quantified performance in the task using a standard signal detection measure called the Area Under the ROC curve (hereafter AUC). The AUC score can be interpreted as the probability that, given two pairs of words (e.g., "apple"/"bread" and "apple"/"horse"), of which one is from the same category (i.e., "apple"/"bread"), the pairs are correctly classified. This probabilistic interpretation indicates that AUC values range between 0.5 (i.e., the cue is performing at chance) and 1 (i.e., the cue is perfect). We derived both a global AUC score across all six categories and a category-specific AUC score where we evaluated only the subset of pairs of words that contained at least an instance of a target category.^[A similar task and evaluation method have been used in previous work to evaluate cues to phonological categories in early development [@fourtassi2013; @fourtassi2014].]


```{r task, fig.env = "figure", fig.pos = "h", fig.align = "center", fig.width=7, fig.height=3, fig.cap = "\\label{fig:task} A schematic description of the task. For each basic-level word (here, `cow') a feature vector is derived from child-directed speech based on how the cue is defined. Here, the vector cells correspond to the superordinate categories. The entry in a given cell (e.g., animal) is incremented when the word `cow' co-occurs with the corresponding category label. The cue is evaluated based on its ability to classify pairs of words into 'same' or 'different' superordinate categories. Here, the pair `cow'-`horse' belongs to the same category. The corresponding vectors should be closer to each other than the vectors of a pair that belongs to different categories (e.g., `cow'-`shirt'). This evaluation is quantified by a standard measure in signal detection theory called the Area Under the ROC Curve (AUC)."}

img <- png::readPNG("figs/task.png")
grid::grid.raster(img)
```


<!--basic-level terms of different super-ordinate categories (the noise). To this end, we evaluate the binary classifier that takes as input a list of pairs of basic-level terms and their cosine similarity, and which returns, as output, a score (called the AUROC) which quantifies the accuracy of the cosine similarity, that is, the extent to which it ranks pairs from the same super-ordinate category ("dog", "cat") higher than pairs from different categories ("dog", "chair").-->

# Results 

## Individual Cue Results

Instances of the most explicit cue type, the *"is-a-kind-of" cue*, were so rare that we could not even build feature vectors for basic-level words. In total, we found only four instances, all of them characterizing the "animal" category. Thus, we did not have meaningful results to report for this cue. As for the other cues, Figure \ref{fig:data-all} shows the global AUC score across categories as well as the AUC scores specific to each category. 

```{r data-all, fig.env = "figure", fig.pos = "h", fig.align = "center", fig.width=7, fig.height=3, fig.cap = "\\label{fig:data-all} The Area Under the ROC Curve (AUC) scores of the cues for each category and across all categories ('ALL'). A value of 0.5 represents pure chance, and a value of 1 represents perfect performance."}

auc_all <- feather::read_feather("../saved/auc_combined.feather") %>%
  rename(category = variable,
           AUC = value,
           cue = mode) %>%
  select(-yr)

auc_all$cue <- mapvalues(auc_all$cue, from = c("w2v", "cooccurrence", "verbs"), to = c("Distributional", "Pragmatic", "Affordance"))
auc_all$category <- mapvalues(auc_all$category, from = c("food_drink", "furniture_rooms", "toys", "animals", "clothing", "vehicles"), to = c("food", "furniture", "toys", "animals", "clothes", "vehicles"))

dev <- feather::read_feather("../saved/aggregate.feather") %>%
  filter(age == 3) %>%
  select(-age) %>%
  mutate(category = "ALL")

dev$cue <- mapvalues(dev$cue, from = c("Co-occurrence", "Pragmatic", "Affordance"), to = c("Distributional", "Pragmatic", "Affordance"))

auc_all <- auc_all %>%
  bind_rows(dev)

auc_all$cue <- factor(auc_all$cue, levels = c("Pragmatic", "Affordance", "Distributional"))

auc_all$category <- factor(auc_all$category, levels = c("animals", "clothes", "food", "furniture", "toys",  "vehicles", "ALL"))

ggplot(data=auc_all, aes(x=category, y=AUC, fill=cue)) +
  geom_bar(stat="identity", position=position_dodge()) +
  #geom_bar(data = filter(auc_all, category =='ALL'), stat="identity", position=position_dodge(), alpha=0.5)+
    ylim(0, 1) + 
  geom_hline(yintercept=0.5, linetype = "dashed") +
    theme_few()+
    theme(legend.title = element_text(size=11),
      legend.text=element_text(size=11),
      axis.text = element_text(size = 11, angle = 45))
 
    
```

The accuracy of the *pragmatic cue* was generally low. For this cue, we only report the results with $k=1$, which captures relations between basic and superordinate words within a single utterance. Increasing the value of $k$ has led to worse, noisier performance. Regarding the *affordance-based cue*, the accuracy was relatively high for some categories, i.e., "food", "clothes", "vehicles," and "toys" and low for others, i.e., "furniture" and "animal." Finally, the *distributional cue* leads to the best overall results across most superordinate categories.

<!-- \begin{table}[!htbp] \centering  -->
<!-- \caption{\label{tab:regressions} Logistic regressions predicting the binary classification of pairs of basic-level words as belonging to same or different superordinate categories. The predictors are the pairs' similarity measures derived from each cue. We fit a different regression for each superordinate category.}  -->
<!-- \label{}  -->
<!-- \begin{tabular}{@{\extracolsep{5pt}}lcccccc}  -->
<!-- \hline  -->
<!--  & \multicolumn{6}{c}{} \\ -->
<!--  & Animals & Furniture & Toys & Food & Clothing & Vehicles \\  -->
<!-- \hline \\[-1.8ex]  -->
<!--  (Intercept) & $-$2.741$^{***}$ & $-$3.195$^{***}$ & $-$3.244$^{***}$ & $-$2.616$^{***}$ & $-$3.101$^{***}$ & $-$4.663$^{***}$ \\  -->
<!--   & (0.085) & (0.138) & (0.155) & (0.112) & (0.183) & (0.348) \\  -->
<!--   & & & & & & \\  -->
<!--  Co-occurrence & 2.285$^{***}$ & 2.040$^{***}$ & 1.178$^{***}$ & 0.905$^{***}$ & 1.644$^{***}$ & 1.249$^{***}$ \\  -->
<!--   & (0.074) & (0.127) & (0.136) & (0.060) & (0.171) & (0.193) \\  -->
<!--   & & & & & & \\  -->
<!--  Affordance & 0.022 & 0.547$^{***}$ & 0.620$^{***}$ & 2.112$^{***}$ & 1.535$^{***}$ & 2.211$^{***}$ \\  -->
<!--   & (0.057) & (0.094) & (0.113) & (0.092) & (0.153) & (0.245) \\  -->
<!--   & & & & & & \\  -->
<!--  Pragmatic & 0.179$^{***}$ & $-$0.104 & 0.722$^{***}$ & 0.325$^{***}$ & 0.359$^{*}$ & 0.159 \\  -->
<!--   & (0.050) & (0.080) & (0.120) & (0.059) & (0.146) & (0.138) \\  -->
<!--   & & & & & & \\  -->
<!--  \\[-1.8ex]  -->

<!-- \hline \\[-1.8ex]  -->
<!-- \textit{Note:}  & \multicolumn{6}{r}{$^{*}$p$<$0.05; $^{**}$p$<$0.01; $^{***}$p$<$0.001} \\  -->
<!-- \end{tabular}  -->
<!-- \end{table} -->




<!--Thus, this cue can only be informative statistically, i.e., if words from a given super-ordinate category (e.g., "Juice")  co-occur more with the label of this category (i.e., "food") than they do with the label of another category (e.g., "clothes"). -->

## Developmental change?

<!--The results we showed concern cues derived from parental speech to children up to 3
years old, as this is the age when signs of conceptual hierarchy start
to emerge in the developmental literature. But -->


<!-- The main goal of the current study is to quantify the linguistic cues that children could use to initiate the learnig of conceptual hiererachy in their emerging lexicon. -->

The results above are based on child-directed speech up to three years old. As we mentioned earlier, this choice was based on research showing that this is the age when early signs of conceptual hierarchy emerge in children's lexicon. That said, several studies have documented changes in child-directed speech beyond 3 years [e.g., @jiang2022exploring; @huttenlocher2010sources; @kunert2011adaptation], and here we ask whether and how our linguistic cues undergo changes as children grow older and their linguistic input gets richer. While previous work does not make direct predictions about what could change regarding our specific cues, one can expect, e.g., that the distributional cue would become even stronger because the accumulation of more data in an increasing number of contexts would make more accurate the detection of shared patterns of co-occurrence. As for the pragmatic and affordance-based cues, we did not have a priori expectations about whether their role would become more or less important with development.

We followed the same approach as above but with data addressed to children up to 4, 5, and 6 years old, respectively. We stopped at 6 years old as this the age after which data become very sparse in the dataset CHILDES) (Table \ref{tab:development}). This cumulative way to study change (e.g., data up to 4 years old include data up to 3 years old) parallels the cumulative nature of children's linguistic experience.  The results are summarized in Figure \ref{fig:dev}: They show that the performance of all cues remained stable across development (including for the distributional cue), suggesting that linguistic information in parental talk regarding conceptual hierarchy is already at ceiling by 3 years of age. More linguistic input does not change the informativeness of the cues. 

\begin{table}[!htbp] \centering 
\caption{\label{tab:development} Information about the corpora used in the analysis of developmental change.}
\begin{tabularx}{\linewidth}{cXccXX}

\textbf{Age} & Age (months) & Children & Transcripts & Utterances & Words \\
\hline

\textbf{\textless4} & 30.1 & 843 & 6,750 & 2.657 M & 10.827 M\\

\textbf{\textless5} & 33.5 & 971 & 7,889 & 3.093 M & 12.807 M\\

\textbf{\textless6} & 34.8 & 1,046 & 8,654 & 3.221 M & 13.325 M\\

\hline
\end{tabularx}

\end{table}


```{r dev, fig.env = "figure", fig.pos = "!htbp", fig.align = "center", fig.width=3, fig.height=3, fig.cap = "\\label{fig:dev} The Area Under the ROC Curve (AUC) scores for each cue (across all categories) using speech heard by children up to a particular age. A value of 0.5 represents pure chance, and a value of 1 represents perfect performance."}

dev <- feather::read_feather("../saved/aggregate.feather") 

ggplot(data=dev, aes(x=age, y=AUC, col=cue)) +
  geom_point(position=position_dodge()) +
    geom_line() +
    ylim(0, 1) + 
  geom_hline(yintercept=0.5, linetype = "dashed") +
    theme_few()+
    theme(
      aspect.ratio=0.7,
      legend.title = element_text(size=7),
      legend.text=element_text(size=7),
      axis.text = element_text(size = 11)
      ) +
    theme(legend.position = c(0.99, 0.01),
      legend.justification = c("right", "bottom"),
      legend.key.size = unit(0, 'lines'))

```

## Cross-cue results 

The analyses above explored how the cues fare individually. Here we investigate the extent to which they provide complementary vs. redundant information when combined. To this end, we fit six logistic regressions, one for each superordinate category. In all the regressions, the dependent variable was the binary classification of pairs of basic-level words belonging to same or different superordinate categories. The independent variables were the four similarity measures derived from the four cues. The results of the regressions,
summarized in Table \ref{tab:regressions}, indicate that, overall, each cue remains highly significant when controlling for the other cues. Thus, overall, the cues provided _non-redundant_ information to category membership.
<!--and the overall classification performance increased when multiple information sources were used.
-->

\begin{table}[!htbp] \centering 
\caption{\label{tab:regressions} Logistic regressions predicting the binary classification of pairs of basic-level words as belonging to same or different superordinate categories. The predictors are the pairs' similarity measures derived from each cue. We fit a different regression for each superordinate category. The predictors were centered and scaled for comparability.} 
\label{} 
\begin{tabular}{@{\extracolsep{5pt}}lcccccc} 
\hline 
 & \multicolumn{4}{c}{} \\
 & (Intercept) & Distributional & Affordance & Pragmatic \\ 
\hline \\[-1.8ex] 
  Animals & $-$2.741$^{***}$ & 2.285$^{***}$ & 0.022 & 0.179$^{***}$\\
  & (0.085) & (0.074) & (0.057) & (0.050)\\
  & & & & & & \\
  Furniture & $-$3.195$^{***}$ & 2.040$^{***}$ & 0.547$^{***}$ & $-$0.104\\
  & (0.138) & (0.127) & (0.094) & (0.080) &\\
  & & & & & & \\
  Toys & $-$3.244$^{***}$ & 1.178$^{***}$ &  0.620$^{***}$ & 0.722$^{***}$\\
  & (0.155) & (0.136) & (0.113) & (0.120) &\\
  & & & & & & \\
  Food & $-$2.616$^{***}$ & 0.905$^{***}$ & 2.112$^{***}$ & 0.325$^{***}$\\
  & (0.112) & (0.060) & (0.092) & (0.059)\\
  & & & & & & \\
  Clothing & $-$3.101$^{***}$ & 1.644$^{***}$ & 1.535$^{***}$ & 0.359$^{*}$\\
  & (0.183) & (0.171) & (0.153) & (0.146)\\
  & & & & & & \\
  Vehicles & $-$4.663$^{***}$ & 1.249$^{***}$ & 2.211$^{***}$ & 0.159\\
  & (0.348) & (0.193) & (0.245) & (0.138)\\
  & & & & & & \\
 \\[-1.8ex] 

\hline \\[-1.8ex] 
\textit{Note:}  & \multicolumn{6}{r}{$^{*}$p$<$0.05; $^{**}$p$<$0.01; $^{***}$p$<$0.001} \\ 
\end{tabular} 
\end{table}

# Discussion

A crucial question in the study of both language and cognitive development is understanding how children acquire the complex hierarchical relationships that characterize mature human semantic knowledge. A particularly challenging task is learning how basic-level terms are related to abstract superordinate concepts. One difficulty of this task stems from the fact that first-hand perceptual experience does not always provide direct evidence for learning, e.g., superordinate category, in particular, often requires additional social input that indicates how the child's specific linguistic community carves up the world into concepts [e.g., @waddy1982, @gelman2009; @harris2012, @csibra2009]. The current work is a first step to investigating the extent to which *language* that children hear around them can provide explicit or implicit cues about conceptual hierarchy. The main novelty of our work is that we used a unified computational framework that has allowed us to directly compare the relative importance of different linguistic cues present in child-directed speech with respect to their ability to help learn the taxonomic relations linking basic-level words in children's emerging lexicon to six common superordinate categories. 

<!--Overall, we found that caregiver talk provides a rich source of information, especially in its implicit form, that children may use in learning category structure.-->

## The relative usefulness of cues to conceptual hierarchy in child-directed speech 

The most explicit cue -- where caregivers state the relationship between a basic-level term and its superordinate category label (e.g., "a dog is a kind of animal") -- did not scale up well to the naturalistic dataset we used. This finding contrasts with previous work that found this cue in parental speech [@callanan1985; @shipley1983]. This contrast can be explained by the fact that these previous studies were done in the context of rather controlled settings and parents were aware of the task (e.g., teaching words at the superordinate level), whereas here we tested a corpus of largely *spontaneous* speech. 

<!--Thus, it is possible that, in these previous studies, parents used a teaching strategy that they thought could optimize the short-term outcome (as determined by the experimenter), rather than a strategy that reflects their spontaneous interaction with children in daily life.-->

<!--Here we used a distributional approach to compare the relative importance of different information sources in the categorization of six common superordinate categories. We found that distributional information (as captured by Word2Vec models) and verb affordances were effective and that -- to a lesser extent -- sentential co-occurrence with superordinate labels also contributed positively to classification. Thus, at a high level, our study confirms the utility of caregiver talk for conveying conceptual information and suggests that a rich range of linguistic cues may be available to children in the learning category structure. -->

Caregivers can hint at conceptual hierarchy without necessarily stating it explicitly, however (see Table 1).  To capture this pragmatic cue, we quantified the co-occurrence between basic-level and superordinate terms within utterances. This simple operationalization was meant to capture all possible ways the hierarchical relationship between two concepts can be expressed linguistically. However, it also made the representation susceptible to errors, mainly by increasing the rate of false alarms: A basic level term (e.g., "juice") can also co-occur with a superordinate label of which it is not an instance (e.g., "Don't pour the juice on your clothes!"). The rate of such false alarms was quite high, which explains the overall low  -- though not random -- scores of this cue. 

From a developmental point of view, this finding highlights the limitation (at scale) of a simple co-occurrence-based strategy: A deeper understanding of the meaning of the utterance is necessary if children are to learn conceptual hierarchy from pragmatic cues while avoiding false alarms. Future work should aim at providing a more refined computational implementation of these cues. While the ability of state-of-the-art language models in making general, reliable pragmatic inference is still poor, modeling work in Natural Language Processing that has focused on the specific task of inferring taxonomic relations from textual data has been more fruitful [e.g., @chami2022machine; @le2019inferring; @zhang2022aser]. While this literature has not yet managed to reliably extract taxonomic relations from pairs of terms in a sentence when the relation is not linguistically explicit (i.e., as defined in the pragmatic cue), the methods developed – when relevant and cognitively plausible – can be a source of inspiration for researchers in child development to improve the study of children’s linguistic input in terms of inferring conceptual structure more generally.

<!--Future work can aim at quantifying such deeper understanding. That said, this is not an easy task since an _automatic_ method that ``understands'' how words are related both semantically and pragmatically is an open computational question.-->

Another linguistic cue we tested is based on affordances (e.g., basic-level terms for food are "eat"-able and can be detected as such if they occur as the grammatical object of the verb "eat"). The accuracy of the affordance-based cue was relatively high for the categories which had an obvious verb to cue its affordance, i.e., "food" (eat), "clothes" (wear), "vehicles" (ride), and "toys" (play). The accuracy was low in the case of "furniture" since the verb "use" is not exclusive to this category and can also be used with instances of other categories, leading to false alarms. The accuracy for "animal" was also low as it was not characterized by any particular verb. \footnote{At the same time, the performance of the cue on this category was not totally random because animal instances tend to co-occur more consistently with some verbs from other categories (e.g., "ride a horse", "play with the dog", and "eat the chicken").} 

Finally, the pure distributional cue was the most implicit one since it did not rely on a label or any other linguistic marker for the abstract category. The score for this cue was generally high, including for "animal" and "furniture," two categories that were not reliably captured with any of the previous cues. This finding suggests that children can learn that certain basic-level terms share common abstract properties by realizing that they have a similar distribution in speech, i.e., that they are used in similar linguistic contexts. This strategy could be even more useful for high-level categories that do not have an explicit label, or for which the label could not be available to the young learners (e.g., "animate" vs. "inanimate").

In addition to these insights obtained by testing each cue individually, we also tested how the cues interact with one another when they were all combined to predict learning in each superordinate category. We found that the cues were largely non-redundant across most categories, suggesting that children can combine several cues to complement their learning. Further, the cues did not fare similarly across categories, suggesting that children can rely more on different cues to learn different categories, e.g., they may use the affordance-based cue more to learn about "food", "clothes" or "vehicle" and the distributional cue more to learn about "animals" and "furniture." For example, early on, children can learn that some words tend to occur as objects to the verbs "eat," "wear," or "ride." enhancing the learning of these conceptual links. In parallel, and as they accumulate more linguistic experience, they develop increasingly more accurate statistical patterns about which pairs of words share similar distribution in speech, leading to increasingly more refined knowledge about the categories "animals" and "furniture." 

## Possible learning mechanisms

For all the cues discussed above, our goal was to test their ability to provide a reliable source of information in child-directed speech. However, our instantiation of the cues abstracted away from the children's cognitive and information processing limitations, providing only an "ideal observer" point of view [@marr1982]. That said, several experimental studies have provided evidence for the cognitive plausibility of the learning mechanisms that underlie each of these cues.  

For instance, preschool children ably use the "is-a-kind-of" cue to interpret the meaning of a novel word at the superordinate level [@callanan1989] (though the current study shows this cue to be highly impoverished in natural input).  Both the pragmatic and affordance-based cues rely on the ability to track co-occurrence between pairs of words: the basic- vs. superordinate-level labels in the former and the basic-level label vs. the verb cueing affordance in the latter. Extensive research in the last couple of decades has shown that even infants are capable of tracking the co-occurrence of various linguistic units [@saffran1996]. In particular, @bannard2008 have shown toddlers encode together in memory collocational words such as "sit" and "chair" and @wojcik2015 have shown that they encode relationships between novel words co-occurring in a sentence. The distributional cue, on the other hand, requires not only sensitivity to word co-occurrence (as with the pragmatic and affordance-based cues) but also sensitivity to the words' _shared_ patterns of co-occurrence. For example, learners should be sensitive to the fact that "raven" and "salmon" co-occur with similar words and phrases such as "lay egg", "live," and "reproduce", although the pair of words "raven" and "salmon" may not themselves co-occur with each other. There is some evidence that even infants are sensitive to shared patterns of co-occurrence [e.g., @lany2011].

Note, however, that while the detection of reliably co-occurring pair of labels can create a mental association (via simple associative mechanisms), it is not clear how this association would develop into becoming a taxonomic relation (as opposed to, say, a thematic relation). In other words, detecting co-occurrence is a necessary but not a sufficient condition for the learning of conceptual *hierarchy*. To make full advantage of the affordance-based cue, it is important to also understand the syntactic relations (i.e., verb-complement structure). For the pragmatic cue, it is crucial to also make inferences about the speaker's intended relationship between basic and superordinate terms given the context. Indeed, the fact that our simple implementation of the pragmatic cue based on mere co-occurrence has led to poor performance is a strong testimony to the need for this additional, higher-level inference. 

As for the pure distributional cue, and when operating alone, there is a priori no additional information (syntactic or extra-linguistic) that can help children induce conceptual hierarchy beyond information about word co-occurrence. On this account, the accumulation of direct co-occurrence in children's memory (e.g., "fruits"-"hungry" and "vegetables"-"hungry") leads to the realization (perhaps triggered by cognitive maturation, e.g., @bauer2010going; @savic2022experience) that some words share similar pattern of co-occurrence (e.g., that "fruits" and "vegetables" co-occur in similar linguistic contexts; in this example, they both co-occur with "hungry"), which then foster the creation of a taxonomic -- rather than a thematic -- link (i.e., "fruits" and "vegetables" are instances of a single higher-level conceptual category, e.g., "food") [@sloutsky2017; @mcneill1963origin; @brown1960word; @ervin1961changes]. It is still not entirely unclear what precise mechanistic process can explain how sensitivity to shared patterns of co-occurrence between two labels may give rise to a taxonomic link relating these labels to a single superordinate category, supporting conceptual inference and knowledge generalization, but we refer the reader to @unger2021 and @savic2022experience for a review and discussion of some hypothesized mechanisms based on behavioral, computational, and/or neuroscientific evidence.

## Conclusion and future work 

This work studied how toddlers begin to acquire conceptual hierarchy. While most previous work focused on the role of first-hand observation, here we investigated another (complementary) source of input, i.e., the language children hear around them. We found implicit cues (the affordance-based and distributional cues) to be much more reliable than explicit cues ("is-a-kind-of" and pragmatic cues). While studies have shown that children are cognitively equipped to learn conceptual hierarchy equally from both implicit and explicit cues, our input analysis suggests that implicit cues could be the more important source of this knowledge. 

That said, the current work is only a first step and more work is needed to refine the cues, especially the ones for which we only provided a simple approximation such as the pragmatic cue. In addition, while we emphasized the complementary aspect of linguistic cues compared to perceptual cues, future work should allow direct comparison between these two accounts in order to better estimate the relative role of each source of information in development [e.g., @andrews2014; @bruni2014]. Ultimately, the goal would be to integrate both sources into a _cognitive_ model that uses these cues in a principle way. Such a model should make precise developmental predictions about how the cues interact and how their role in learning changes across development.

Another direction for future work is to compare the findings we obtained with data in English to other languages. Understanding variation in children's experiences allows us to determine which aspects of development are universal and which are culture-specific [@rogoff2018]. The learning of conceptual hierarchy is an excellent case stud; we know for example that superordinate concepts have both similarities and differences across cultures [e.g. @waddy1982]. In addition, the cues may vary in terms of their reliability from one language to the other, depending both on cultural practices/parenting styles and on the specificities of the language. Finally, it is crucial for future work to investigate whether and how variation in caregivers’ language induces variations in children's conceptualization of the world.



<!--Second, we used rough approximations of the potentially more subtle cues that we labeled "pragmatic" and "affordance-based" information. Capturing the structure of knowledge as it is used in natural language is an open computational challenge, but it is possible that more refined cues could improve performance even further. -->

<!--To conclude, our work here suggests the presence of multiple information sources about conceptual structure in children's linguistic environment. Perhaps the most exciting future direction is to synthesize it with knowledge gleaned from children's sensory experience of the world. Such a synthesis will be crucial in making progress in understanding children's conceptual structure. By refining our understanding of linguistic cues to conceptual hierarchy, we hope our work here helps take a first step in this broader project.-->

<!--
[Discuss the fact that previous studies found anchoring in parental speech, but not this studty]
The goal of this preliminary analysis was to explore the extent to which parents' anchoring strategies reported in previous reseach (typically in a controlled context) generalize to a large scale corpus which contains a variety of situations. In a controlled context, parents are explicitly asked to teach their children instances of conceptual hierachy. While this situation allows us to make precise causal inference, it may prompt parents to use a teaching strategy that optimizes the short-term outcome, rather than a strategy that reflects their spontanepous interaction with children in daily life. They showed that the cues 

The genaral conclusion: Anchoring, when narrowly defined, is not frequent enough, and when braodly defined, is too noisy. 
This does not prove that anchoring is not a valid cue, it is possible that children use an intermediate strategy which accept some expressions of anchoring and rejects others as non-informative, thus increasing the coverage while avoiding noise. This is left for further research.


Along the x-axis we have the categories, and on the y-axis is the AUC value for the category. A value of 1 means the model can classify the categories perfectly, while a value of 0.5 means it has no separative capacity.


In many cases, it may not even be necessary to explicitly mention the superordinate category label,

he intuition behind this formalizton is that words from a given super-ordinate category (e.g., "apple") should co-occur more with the label of this category (i.e., "food") than they do with the label of another category (i.e., "toys"), and thius 


should be more similar to each other than they are to words form another category, i.e.,

(which, in addition, allows us to use)

To determine whether anchoring is a viable cue for the acqusition of conceptual hoerachy, we need to show that the probability of the occurrence of a given super-ordiante categories (e.g., "food") should be higher with their basic-level instances (e.g., "apple") than with instances of different category (e.g., "dog"). Using terms from signal detection theory, the anchoring "signal" should be above "noise".

To conrtrol for this confound (This choice was also motivated by our desire to compare anchoring strategies with bottom-up strategies) We represent each basic-level term with a vector. The dimension of this vector is 5; corresponding to the 5 super-ordinate categories. Each entry in the vector correponds to the frequency with which the basic-level term co-occurs with the super-ordinate term at hand. As is standard in the literature on vectorial word representations, we use the cosine between two vectors (i.e.,  their normalized dot product) as a measure of their similarity. 



We quantify the anchoring strategy by its ability to distinguish basic-level terms of the same super-ordinate category (the signal) from basic-level terms of different super-ordinate categories (the noise). To this end, we evalute the binary classifier that takes as input a list of pairs of basic-level terms and their cosine similarity, and which returns, as output, a score (called the AUROC) which quantifies the accuracy of the cosine similarity, that is, the extent to which it ranks pairs from the same super-ordinate category ("dog", "cat") higher than pairs from different categories ("dog", "chair").

Along the x-axis we have the categories, and on the y-axis is the AUC value for the category. A value of 1 means the model can classify the categories perfectly, while a value of 0.5 means it has no separative capacity.

The genaral conclusion: Anchoring, when narrowly defined, is not frequent enough, and when braodly defined, is too noisy. 
This does not prove that anchoring is not a valid cue, it is possible that children use an intermediate strategy which accept some expressions of anchoring and rejects others as non-informative, thus increasing the coverage while avoiding noise. This is left for further research.
--->

```{r }
density_pragmatic <- feather::read_feather("../saved/density_pragmatic.feather")
density_verb <- feather::read_feather("../saved/density_verb.feather")
density_w2v <- feather::read_feather("../saved/density_w2v.feather")

cues_all <- density_w2v %>%
  rename(cooccurrence = value) %>%
  left_join(density_verb) %>%
  rename(affordance = value) %>%
  left_join(density_pragmatic) %>%
  rename(pragmatic = value) %>%
  mutate(gold = ifelse(measure == "within", 1, 0)) %>%
  filter(!(Var1 == Var2)) %>%
  mutate_at(c('cooccurrence', 'affordance', 'pragmatic'), funs(as.numeric(scale(.)))) 

model_all <- glm(gold ~ cooccurrence  + affordance + pragmatic, family=binomial, data = cues_all)

model_animal <- glm(gold ~ cooccurrence  + affordance + pragmatic, family= binomial, data = filter(cues_all, cat1 == "animals"))
model_furniture <- glm(gold ~ cooccurrence  + affordance + pragmatic, family= binomial, data = filter(cues_all, cat1 == "furniture_rooms"))
model_toy <- glm(gold ~ cooccurrence  + affordance + pragmatic, family= binomial, data = filter(cues_all, cat1 == "toys"))
model_food <- glm(gold ~cooccurrence  + affordance + pragmatic, family= binomial, data = filter(cues_all, cat1 == "food_drink"))
model_clothing <- glm(gold ~ cooccurrence  + affordance + pragmatic, family= binomial, data = filter(cues_all, cat1 == "clothing"))
model_vehicle <- glm(gold ~ cooccurrence  + affordance + pragmatic, family= binomial, data = filter(cues_all, cat1 == "vehicles"))
```


```{r results='asis', include =F}
mytable <- stargazer(model_animal, model_furniture, model_toy, model_food, model_clothing, model_vehicle, keep.stat="n",
          omit.stat = c( "n"),
          
          title            = "Logistic regressions predicting category membership as a function of speech-derived cues.",
          dep.var.labels.include = FALSE,
          #style = "qje",
          model.numbers          = FALSE,
          intercept.bottom = FALSE,
          star.cutoffs = c(0.05, 0.01, 0.001),
          column.labels = c("Animals", "Furniture", "Toys", "Food", "Clothing", "Vehicles")
          )
```


# References
```{r create_r-references}
r_refs(file = "library.bib")
```


\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}





